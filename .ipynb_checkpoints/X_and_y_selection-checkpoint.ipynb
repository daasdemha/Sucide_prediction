{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b995cfa",
   "metadata": {},
   "source": [
    "## Downloading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imbalanced-learn used to install imbalanced learn\n",
    "# pip install xgboost # to install xgboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbed2e0",
   "metadata": {},
   "source": [
    "# Make sure the version of anaconda is the latest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46355d5",
   "metadata": {},
   "source": [
    "### Importing the relevent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Allows us to work with arrays.\n",
    "import matplotlib.pyplot as plt  # Allows working with plots.\n",
    "import pandas as pd  # importing pandasâ€™ library for use. Allows us to import data set and manipulate it.\n",
    "\n",
    "import seaborn as sns  # Allows to polt beautiful plots.\n",
    "import matplotlib.pyplot as plt # plotting.\n",
    "from mpl_toolkits import mplot3d  # plotting 3d plots\n",
    "\n",
    "from sklearn.compose import ColumnTransformer  # helps with encoding.\n",
    "from sklearn.preprocessing import OneHotEncoder  # Does onehotencode.\n",
    "from sklearn.preprocessing import LabelEncoder   # Does 1 and 0 encoding.\n",
    "from sklearn.model_selection import train_test_split  # Splits dataset into test set and traning set. \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer  # Perform the feature scaling.\n",
    "from sklearn.linear_model import LogisticRegression  # Performs logistic regression.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, multilabel_confusion_matrix  # creates a \n",
    "                                                                            # confusion matrix  # creates a confusion matrix\n",
    "from sklearn.metrics import accuracy_score  # Returns accury score of a model.\n",
    "from sklearn.neighbors import KNeighborsClassifier  # performs K Neariesst Neighobour.\n",
    "from sklearn.impute import KNNImputer  # imputes missing values using KNN.\n",
    "from sklearn.svm import SVC  # Performs svm\n",
    "from sklearn.naive_bayes import GaussianNB  # performs naive_bayes gaussianNB.\n",
    "from sklearn.tree import DecisionTreeClassifier  #Perfroms decision tree classification model.\n",
    "from sklearn.ensemble import RandomForestClassifier  #Performs random forest classification.\n",
    "from xgboost import XGBClassifier  # performs xgboost classification. gradiant decision trees.\n",
    "from sklearn.linear_model import LinearRegression  # will use to replace missing values linear regressoin\n",
    "from sklearn.decomposition import PCA  # Performs model optimization\n",
    "from sklearn.decomposition import KernelPCA  # Performs model optimization\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA # performs model optimization\n",
    "from sklearn.model_selection import cross_val_score  # performs cross validation. Helps in model selection.\n",
    "from sklearn.model_selection import GridSearchCV  # helps select the best hyper parameters\n",
    "from imblearn.over_sampling import RandomOverSampler  # Uses over sampling techniques to Sample the data correctly.\n",
    "from imblearn.under_sampling import RandomUnderSampler # Uses Under sampling techniques to Sample the data correctly.\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, roc_auc_score, f1_score \n",
    "                                                                                 # Allows the usage of a classification report\n",
    "from sklearn.metrics import precision_recall_fscore_support  # gives precison, recall, f1 score, and support\n",
    "from sklearn.model_selection import RandomizedSearchCV  # performs randomized search cv\n",
    "\n",
    "\n",
    "from collections import Counter  # Allows the counting the items in an iterable list.\n",
    "\n",
    "import warnings  # allows to ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignores warnings\n",
    "\n",
    "#%matplotlib inline  # helps in showing plots on the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f10bfe",
   "metadata": {},
   "source": [
    "# Function to check principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcafuntion(X,pcomponents ,pcolumns, y_value, y_var, plot_labels):  # A function to perfrom PCA with paramenters given.\n",
    "    # Normalizing data before applying pca\n",
    "    sc = StandardScaler()  # creating an instance of the object.\n",
    "    X = sc.fit_transform(X)   # selecting vaues to perfom transformation on  \n",
    "\n",
    "    pca = PCA(n_components=pcomponents)  # selecting number of principal components\n",
    "    principalComponents = pca.fit_transform(X)  #  # selecting values to perfom transformation on  \n",
    "    principalDf = pd.DataFrame(data = principalComponents  # creating a new dataframe with principal components.\n",
    "                 , columns =pcolumns)\n",
    "    finalDf = pd.concat([principalDf, y_value], axis = 1)  # concnating principal componenets with Class.\n",
    "    print(finalDf)  # looking at the out put from pca.\n",
    "    print(\"\\n\",pca.explained_variance_ratio_)# shows how much information is reatined from the pca\n",
    "\n",
    "    missing = 0  # setting variable to 0.\n",
    "    for i in range(len(pca.explained_variance_ratio_)):  # for looping in length of the array pca.explained_variance_ratio_\n",
    "        missing = missing  + pca.explained_variance_ratio_[i]  # adding pca.explained_variance_ratio_[i] \n",
    "                                                              # varables values to missing variable\n",
    "    print(\"Total values :  \", missing, \"%\")  # total data left \n",
    "    missing = 1 - missing  # subtracting missing variables value from 1.\n",
    "    print(\"missing values :\", missing, \"%\")  # total data lost\n",
    "    \n",
    "    \n",
    "    \n",
    "    if pcomponents == 2:  # checks the number of principal components.\n",
    "        plot = sns.relplot(\n",
    "            x='principal component 1', \n",
    "            y='principal component 2', \n",
    "            hue=y_var, \n",
    "            data=finalDf,\n",
    "            facet_kws={'legend_out': False}\n",
    "        )  # plots a scatter plot of principal components.\n",
    "\n",
    "        plt.title('Dataset with pca')  # Title of the plot\n",
    "        # check axes and find which is have legend\n",
    "        leg = plot.axes.flat[0].get_legend()\n",
    "        new_title =y_var  # Legend title.\n",
    "        leg.set_title(new_title)  # setting title to legend.\n",
    "        leg.get_frame().set_alpha(255) # setting transparency level for legend box\n",
    "        labels = plot_labels  # label list for legend\n",
    "        for t, l in zip(plot._legend.texts, labels):  # looping through a touple.\n",
    "            t.set_text(l)  # adding label to list\n",
    "    \n",
    "    elif pcomponents == 3:  # checks the number of principal components.\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))  # setting plot size\n",
    "        ax = plt.axes(projection='3d')  # specifying that it is a 3d plot.\n",
    "        plt.title('Dataset with pca', fontsize=20)  # adding a title to the plot\n",
    "        # Data for three-dimensional scattered points\n",
    "        xdata = finalDf['principal component 1']  # selecting first princal component.\n",
    "        ydata = finalDf['principal component 2']  # selecting second princal component.\n",
    "        zdata = finalDf['principal component 3']  # selecting third princal component.\n",
    "        ax.scatter3D(xdata, ydata, zdata, c=y_value)  # plotting princhpla components\n",
    "\n",
    "        ax.set_xlabel(\"First Principal Component\",fontsize=15)  # setting label for first principal componenet.\n",
    "        ax.set_ylabel(\"Second Principal Component\",fontsize=15)  # setting label for second principal componenet.\n",
    "        ax.set_zlabel(\"Third Principal Component\",fontsize=15)  # setting label for third principal componenet.\n",
    "\n",
    "        plt.show()  # making plot visible.\n",
    "        \n",
    "    return finalDf  # returning finalDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0332511",
   "metadata": {},
   "source": [
    "#  Function to replace missing values Using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missng_values_filler_knn(missingdataframevalue,colname):  # function replaces missing values using KNN's. function \n",
    "                                                              # name specified and paramaters given\n",
    "    columntobereplaced = missingdataframevalue.to_numpy()   # The column to be replaced is stored in a variable.\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")  # creating instance of the object.\n",
    "    replaced = imputer.fit_transform(columntobereplaced).astype(np.int64)  # fitting the model and replaing missing values\n",
    "                                                                        # converting float to int.\n",
    "    print(len(replaced))  # printing replaced lenght\n",
    "    dataframe=pd.DataFrame(replaced, columns=colname)  # adding replaced values in a dataframe column and giving the column a \n",
    "                                                      # name.\n",
    "    print(\"null values \", dataframe.isnull().sum()) # Checking the dataframe for null values.\n",
    "    print(dataframe.head(5))  # printing head of new data frame\n",
    "    return dataframe  # returning the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1ce02",
   "metadata": {},
   "source": [
    "# Function to perform OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5784c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodingoh(required_column,dropped_column,column_rename):  # function to perform the one hot encoding with parameters given.\n",
    "    oh = OneHotEncoder(drop=dropped_column,dtype=np.int)  # creates the instace of the object.\n",
    "    newdf = required_column  # creates a new data frame from the column to be one hot encoded\n",
    "    newdf = oh.fit_transform(newdf).toarray()  # one hot enocdes the new dataframe as a array\n",
    "    newdf = pd.DataFrame(newdf)  # converts the newly created array to a dataframe.\n",
    "    newdf.columns = column_rename  # renames the newly encoded column\n",
    "    print(newdf.head(5))  # outputs the head of the dataframe.\n",
    "    return newdf  # returns the one hot encoded data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c5c32",
   "metadata": {},
   "source": [
    "### Importing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985866e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = pd.read_csv(\"suicidedataextrafestures.csv\")  # opens csv files and assighns them to a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d2088",
   "metadata": {},
   "source": [
    "### Checking the data from the dataframe before pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb046731",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head(1)  # Taking a look at the dataframe the first elements of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dda0c0",
   "metadata": {},
   "source": [
    "### checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(sucidedataframe.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b27895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da515d3",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below relevent data is selected that will be used in this project.\n",
    "sucidedataframe = sucidedataframe[[\"country\", \"age\" ,\"sex\", \"population\",  \\\n",
    "\"Individuals using the Internet (% of population)\", \"Labor force, total\", \\\n",
    "\"Mobile cellular subscriptions (per 100 people)\", \"GDPpyear\",\"GDPpcapital\",\"Expense (% of GDP)\",\\\n",
    "\"Physicians (per 1,000 people)\",\"Refugee population by country or territory of origin\" ,\"suicidesper100k\"]]## 1. Data \n",
    "                                                                                                          # pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92fd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head(5)  # out puts data from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below the col names are renamed.\n",
    "sucidedataframe = sucidedataframe.set_axis([\"Country\", \"Age\", \"Gender\", \"Population\", \\\n",
    "\"Internet_Usage_per_percent_Population\", \"Total_Labour_force\", \"Cellular_subscriptions_per_100_people\", \\\n",
    "\"GDPpyear\",\"GDPpcapital\",\"Expense_percent_of_GDP)\",\\\n",
    "\"Physicians_per_1,000_people)\",\"Refugee_population_by_country_or_territory_of_origin\" ,\"Suicidesper100k\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14a5e9",
   "metadata": {},
   "source": [
    "### initial plot to visulize the data before working on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd819a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (13, 7)\n",
    "plt.style.use('seaborn-white')\n",
    "sns.catplot(x='Gender', y=\"Suicidesper100k\", col=\"Age\", col_wrap=3, sharey=True, data=sucidedataframe, alpha=0.5, palette = 'hot')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_plot_object = sns.FacetGrid(sucidedataframe , row = 'Gender',col = 'Age',margin_titles=True)\n",
    "My_plot_object.map(plt.scatter,\"Suicidesper100k\",'Population',edgecolor = 'w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.columns  # The columns of the dataframe are viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72482132",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.shape  # The Entries and the columns of the dataframe are viewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b358d",
   "metadata": {},
   "source": [
    "### Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(sucidedataframe.isnull())  # shows null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.isnull().sum()  # Checking the dataframe for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking basic information on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19484c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Internet_Usage_per_percent_Population'] = df['DataFrame Column'].fillna(mean(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sucidedataframe.Internet_Usage_per_percent_Population))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aca313",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sucidedataframe.Refugee_population_by_country_or_territory_of_origin))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sucidedataframe[\"Expense_percent_of_GDP)\"]))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e90761",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sucidedataframe[\"Physicians_per_1,000_people)\"]))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe[[\"Internet_Usage_per_percent_Population\"]] = missng_values_filler_knn(sucidedataframe[[\"Internet_Usage_per_percent_Population\"]], [\"Internet_Usage_per_percent_Population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723848e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values using KNN function\n",
    "sucidedataframe[[\"Expense_percent_of_GDP)\"]] = missng_values_filler_knn(sucidedataframe[[\"Expense_percent_of_GDP)\"]], [\"Expense_percent_of_GDP)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values using KNN function\n",
    "sucidedataframe[[\"Refugee_population_by_country_or_territory_of_origin\"]] = missng_values_filler_knn(sucidedataframe[[\"Refugee_population_by_country_or_territory_of_origin\"]],[\"Refugee_population_by_country_or_territory_of_origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values using KNN function\n",
    "sucidedataframe[[\"Physicians_per_1,000_people)\"]] = missng_values_filler_knn(sucidedataframe[[\"Physicians_per_1,000_people)\"]],[\"Physicians_per_1,000_people)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.isnull().sum()  # Checking the dataframe for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.dropna() # droping all rows with at least one null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73657dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sucidedataframe.reset_index(drop=True, inplace=True)  # reseting index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sucidedataframe.isnull().sum()  # Checking the dataframe for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.shape  # The Entries and the columns of the dataframe are viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439de35b",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.nunique()  # outputs unique values in each column in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c425de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.duplicated().sum()  # gives the sum of duplicate dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Gender'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05679549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Country'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head(1)  # outputs the head of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfef85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Age'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1656f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.index = pd.RangeIndex(len(sucidedataframe.index))  # outputs indext of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9602b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c742a",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Gender'], aggfunc='size'))  # prints the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Age'], aggfunc='size'))  # prints the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bae9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  one hot enocdes the column using the created function.\n",
    "age = encodingoh(sucidedataframe[[\"Age\"]], None, ['15-24 years',\"25-34 years\", \"35-54 years\", \"5-14 years\", \"55-74 years\", \"75+ years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  one hot enocdes the column using the created function.\n",
    "gender = encodingoh(sucidedataframe[[\"Gender\"]], \"first\", [\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88555276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.drop('Age', 1)  # column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5fe188",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.drop('Gender', 1)   # column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51efce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head(5)  # dataframe head is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = pd.concat([ gender,sucidedataframe],axis=1)  # column is concatanated to dataframe\n",
    "sucidedataframe.head()  # fisrt elements of the dataframe are outptted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = pd.concat([age,sucidedataframe],axis=1)  # column is concatanated to dataframe\n",
    "sucidedataframe  # fisrt elements of the dataframe are outptted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Gender'], aggfunc='size'))   # prints the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d351b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['15-24 years'], aggfunc='size'))  # counts duplicates in the selected \n",
    "                                                                             # dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aced977",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"25-34 years\"], aggfunc='size'))  # counts duplicates in the selected \n",
    "                                                                             # dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb123e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"35-54 years\"], aggfunc='size'))  # counts duplicates in the \n",
    "                                                                        # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"5-14 years\"], aggfunc='size'))  # counts duplicates in the\n",
    "                                                                            # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24042f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"55-74 years\"], aggfunc='size'))  # counts duplicates in the \n",
    "                                                                            # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd610a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"75+ years\"], aggfunc='size'))  # counts duplicates in the \n",
    "                                                                        # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head()  # the first elements of the data frame are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373eceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.describe().round()  # Shows the count, mean, std, min, 25%, 50%, 75% and \n",
    "                                    # max of a datframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))  # sets the size of the matrix\n",
    "correlation_matrix = sucidedataframe.corr().round(2)  # creates the correlation matrix\n",
    "sns.heatmap(data = correlation_matrix, annot = True)  # shows correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix = sucidedataframe[[ \"Gender\", \"5-14 years\", \"15-24 years\", \"75+ years\"]]  # higher correlated \n",
    "                                                                                                       # features are selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix.head()  # first elements of the dataframe are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count duplicates function learned from: https://datatofish.com/count-duplicates-pandas/\n",
    "sucidedataframe.pivot_table(columns=['Country'], aggfunc='size')  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_country = np.unique(sucidedataframe[[\"Country\"]].values) # unique country rows are selected.\n",
    "each_country  # array is outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Country = encodingoh(sucidedataframe[[\"Country\"]], None, each_country)  # each country is one hot encoded at a time.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = pd.concat([Country,sucidedataframe],axis=1)  # each new country is concatanated to original data frame.\n",
    "sucidedataframe.head() # first elements of the data frame are out putted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix = pd.concat([Country,Features_after_corelation_matrix],axis=1)  # each new country is \n",
    "                                                                     # concatanated to highly correlate data frame.\n",
    "Features_after_corelation_matrix.head()   # first elements of the data frame are out putted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40411854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.columns)  # columns of the data frame are printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.drop('Country', 1)  # country column is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.columns)  # columns of the data frame are printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0330f",
   "metadata": {},
   "source": [
    "### Making lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.describe().round()  # Shows the count, mean, std, min, 25%, 50%, 75% and \n",
    "                                    # max of a datframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f8159",
   "metadata": {},
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919eec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max :   \", 178 )\n",
    "print(\"high :  \", round(178 / 2))\n",
    "print(\"medium :\", round(89 / 2))\n",
    "print(\"low :   \", round(44 / 2))\n",
    "print(\"min :   \", round(22 / 2))\n",
    "\n",
    "\n",
    "# enogh data catagories to model\n",
    "# model is not computationally heavy\n",
    "\n",
    "# when you do neural networks the solution that you reach is a local minimum. you dont know if you reach a global minimium \n",
    "\n",
    "# pca \n",
    "# igon values tell each values contained in the igon vector(linear combanation of our data).\n",
    "\n",
    "# 90 % of igon values\n",
    "\n",
    "# pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78341c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] < 11), \"Suicidesper100k\"] = 1 # Encoding values below 11 as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 11) & (sucidedataframe[\"Suicidesper100k\"] < 22), \"Suicidesper100k\"] = 2  \n",
    "# Encoding values aboveor equal to 11 as and below 22 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 22) & (sucidedataframe[\"Suicidesper100k\"] < 44), \"Suicidesper100k\"] = 3 \n",
    "# Encoding values equal to and above 22 and below 44 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b92351",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 44) & (sucidedataframe[\"Suicidesper100k\"] < 89), \"Suicidesper100k\"] = 4  \n",
    "# Encoding values above or equal to 44 as and below 89 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a484a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 89) & (sucidedataframe[\"Suicidesper100k\"] <= 178), \"Suicidesper100k\"] = 5 \n",
    "# Encoding values above or equal to 89 as and below 178 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980cba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()  # creating the instance of the object.\n",
    "sucidedataframe.Suicidesper100k = le.fit_transform(sucidedataframe.Suicidesper100k)  # label encoing the require dcolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6863ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Suicidesper100k'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b383abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "9264 + 2850 + 2177 + 678 + 141  # calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head()  # outputting dataframe head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfafc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = str(round(100 * (9264/15110),2)) + \"%\"   # percentage of the value is checked from label column.\n",
    "two  = str(round(100 * (2850/15110),2)) + \"%\"  # percentage of the value is checked from label column.\n",
    "three = str(round(100 * (2177/15110),2)) + \"%\"  # percentage of the value is checked from label column.\n",
    "four = str(round(100 * (678/15110),2)) + \"%\"  # percentage of the value is checked from label column.\n",
    "five = str(round(100 * (141/15110),2)) + \"%\"  # percentage of the value is checked from label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b25d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1 is represented \", one, \"\\n2 is represented \", two, \"\\n3 is represented \", three, \"\\n4 is represented \", four, \"\\n5 is represented \", five)\n",
    "# percentage of the value is printed of label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([1,2,3,4,5],[9262, 2850, 2177, 678, 141])  # bar chart is outputted to show the difference in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3732425",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head()  # dataframe head is outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d914b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe['Cellular_subscriptions_per_100_people'] = sucidedataframe['Cellular_subscriptions_per_100_people'].astype(np.int64)  # converting float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f353660",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe['Suicidesper100k'] = sucidedataframe['Suicidesper100k'].astype(np.int64)  # converting float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe['GDPpyear'] = sucidedataframe['GDPpyear'].astype(np.int64)  # converting float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8202e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe['Expense_percent_of_GDP)'] = sucidedataframe['Expense_percent_of_GDP)'].astype(np.int64)  # converting float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe['Physicians_per_1,000_people)'] = sucidedataframe['Physicians_per_1,000_people)'].astype(np.int64)  # converting float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe['Refugee_population_by_country_or_territory_of_origin'] = sucidedataframe['Refugee_population_by_country_or_territory_of_origin'].astype(np.int64)  # converting float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f370496",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5602f",
   "metadata": {},
   "source": [
    "### selecting X and Y values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a48807",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.head(1)  # the fisrt elements of the data frame are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix.head(1)  # the fisrt elements of the data frame are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sucidedataframe.iloc[:, :-1].values  # selecting the values for the X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = Features_after_corelation_matrix.iloc[:, :].values # selecting the \n",
    "                                                                                        # values for the X2 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sucidedataframe.iloc[:, -1].values # selecting the values for the Y variable. # done using .to_numpy and not \n",
    "                                                       # .iloc as .to_numpy creates a horizontal bar while .iloc creates a \n",
    "                                                       # horizontal bar which will not alighn with the x values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X \", X, \"\\n\", \"X2 \" , X2 , \"\\n\", \"y \", y)  # priting arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf6de1",
   "metadata": {},
   "source": [
    "# Principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb5858",
   "metadata": {},
   "source": [
    "## Using continues variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03199c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = sucidedataframe.iloc[:, 55:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87077483",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafuntion(X_pca,2 ,['principal component 1','principal component 2'], sucidedataframe[[\"Suicidesper100k\"]], \"Suicidesper100k\", [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafuntion(X_pca,3 ,['principal component 1','principal component 2', 'principal component 3'], sucidedataframe[[\"Suicidesper100k\"]], \"Suicidesper100k\", [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0954466a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pcom = \"principal component \"\n",
    "plist = ['principal component 1','principal component 2', 'principal component 3']\n",
    "for i in range(4,10):\n",
    "    plist.append(pcom + str(i))\n",
    "    print(\"Number of Components \", i)\n",
    "    pcafuntion(X_pca,i ,plist, sucidedataframe[[\"Suicidesper100k\"]], \"Suicidesper100k\", [1,2,3,4,5])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07f9f0",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original dataset shape %s' % Counter(y))  # original data set rows counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df507fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)  # instance of object created.\n",
    "X_over, y_over = ros.fit_resample(X, y)  # oversampling model fitting\n",
    "print('Resampled dataset shape %s' % Counter(y_over))  # oversampled data set rows counted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c97b77",
   "metadata": {},
   "source": [
    "## Spliting the datasets into a training and test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8539b3c",
   "metadata": {},
   "source": [
    "## Original x and y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2295a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "# test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                            # to get the best results.                                                           \n",
    "# random_state = 1         # resetting the  random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e3915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the lenghth of both test and train set to see if there equally split.\n",
    "print(\"The length of X_train is \",len(X_train), \" and the length of y_train is \", len(y_train))  \n",
    "print(\"The length of X_test is \",len(X_test), \" and the length of y_test is \", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d558b",
   "metadata": {},
   "source": [
    "## Original x and y values after they have been over Sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over, test_size = 0.2, random_state = 1)\n",
    "# test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                            # to get the best results.                                                           \n",
    "# random_state = 1         # resetting the  random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f165b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the lenghth of both test and train set to see if there equally split.\n",
    "print(\"The length of X_train_over is \",len(X_train_over), \" and the length of y_train_over is \", len(y_train_over))  \n",
    "print(\"The length of X_test_over is \",len(X_test_over), \" and the length of y_test_over is \", len(y_test_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8237e",
   "metadata": {},
   "source": [
    "## x2 and y2  values choosend by using the corelation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size = 0.2, random_state = 1)\n",
    "# test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                            # to get the best results.                                                           \n",
    "# random_state = 1         # resetting the  random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdaa413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the lenghth of both test and train set to see if there equally split.\n",
    "print(\"The length of X2_train is \",len(X2_train), \" and the length of y2_train is \", len(y2_train))\n",
    "print(\"The length of X2_test is \",len(X2_test), \" and the length of y2_test is \", len(y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
