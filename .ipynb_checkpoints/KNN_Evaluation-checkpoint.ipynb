{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5295efae",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run X_and_y_selection.ipynb  #  importing a .ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0905e",
   "metadata": {},
   "source": [
    "# Function to evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a95fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_function(model, X_train, y_train,X_test,y_test, title):  # function takes the name of the \n",
    "                                                               # model used, the x and y traning and testing sets.\n",
    "  model.fit(X_train, y_train)  # Building the k-nearest neighbors classification model.\n",
    "\n",
    "  y_test_p = model.predict(X_test)  # Predicted results.\n",
    "  print(\"  results\\npred-Actual\")  # printing predicted and real values.\n",
    "  print(np.concatenate((y_test_p.reshape(len(y_test_p),1),y_test.reshape(len(y_test),1)),1))  # Predicted results and \n",
    "                                                                                       #  real results in a np array.\n",
    "   \n",
    "\n",
    "  train_accuracy = round(model.score(X_train,y_train),2) * 100  # Getting traing accuracy multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100\n",
    "  test_accuracy = round(model.score(X_test,y_test),2) * 100  # Getting testing accuracy multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100\n",
    "\n",
    "  print(\"Model train accuracy: \", train_accuracy, \"%\")  # printing the model accurcy. \n",
    "  print(\"Model test accuracy: \", test_accuracy, \"%\")  # printing the model accurcy. \n",
    "\n",
    "\n",
    "  print(\"\\n\\n\")  # printing a new line.\n",
    "  # getting Accuracy or recall or precision or specificity\n",
    "  y_test_pred = model.predict(X_test)  # predicted results\n",
    "  \n",
    "  cReport = classification_report(y_test,y_test_pred)  # creating a Classification report\n",
    "  print(cReport)  # creating a Classification report\n",
    "  \n",
    "  cm = confusion_matrix(y_test, y_test_p)  # creating the confusion matrix\n",
    "  cm2 = multilabel_confusion_matrix(y_test, y_test_pred)  # creating a mutable confusion matrix\n",
    "\n",
    "\n",
    "  precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_test_pred)  # getting the precision,\n",
    "                                                                                          # recall and f1score for later use.\n",
    "  accuracy  = round(np.trace(cm) / float(np.sum(cm)), 2) * 100  # getting aaccuracy and multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100.\n",
    "  precision = round(np.mean(precision),2) * 100  # multipling precision variables mean by 100 after rounding it by\n",
    "                                                #  2 to get a score between 0 to 100.\n",
    "  recall = round(np.mean(recall),2) * 100  # multipling recall variables mean by 100 after rounding it by 2 to \n",
    "                                           # get a score between 0 to 100.\n",
    "  f1_score = round(np.mean(f1_score),2) * 100  # multipling f1_score variables mean by 100 after rounding \n",
    "                                               # it by 2 to get a score between 0 to 100.\n",
    "\n",
    "  lable_list = []  # creating a empty list\n",
    "\n",
    "  for i in range(len(cm)):  # looping in the range of the length of the confusion matrix.\n",
    "    for j in range(len(cm)):  # looping in the range of the length of the confusion matrix.\n",
    "        if j == i:  # if the value of j is equal to the value of i.\n",
    "            # the below code appends the Actual Values Classified correctly to the variable lable_list.\n",
    "            lable_list.append(\"Actual \"+ str(i) +\"\\n\" + \"calssified as \"+ str(j) +\"\\n\" + str(cm[i][j]) + \"\\n\"+ \\\n",
    "                              str(round(cm[i][j]/np.sum(cm),2)) + \" %\")\n",
    "\n",
    "        else:   # otherwise\n",
    "            #  the below function appends the actual values classified wrongly to the variable lable list.\n",
    "            lable_list.append(\"Actual \"+ str(i) +\"\\n\" + \"calssified as \"+ str(j) + \"\\n\"  + str(cm[i][j]) + \"\\n\"+ \\\n",
    "                              str(round(cm[i][j]/np.sum(cm),2)) + \" %\")\n",
    "\n",
    "            \n",
    "  lable_list = np.asarray(lable_list).reshape(len(cm),len(cm))  # resahping the label list as a numpy array to be \n",
    "                                                                # used in plotting the confusion matrix\n",
    "  \n",
    "  #  the variable function will be will be used to display the results of the evaluation to the confusion matrix.\n",
    "  total_score = (\"Accuracy:   \" + str(accuracy) +\" %\" + \"\\nPrecison:    \"  + str(precision)  +\" %\" + \"\\nRecall:        \" +\\\n",
    "                 str(recall)  +\" %\" + \"\\nF1 score:    \"  + str(f1_score) +\" %\") \n",
    "\n",
    "\n",
    "  # Below is the code used to plot the confusion matrix.\n",
    "  plt.figure(figsize = (12,9))  # sets the size of the matrix\n",
    "  disp = sns.heatmap(cm, annot=lable_list, fmt='', cmap='Blues')  # displays the results of the actual values \n",
    "                                                                 #  classified wrongly and correctly.                       \n",
    "  disp.plot()  # displaying data in plot\n",
    "  plt.title(title, fontsize=25)  # adding a title to plot\n",
    "  plt.ylabel('True label', fontsize=20)  # adding a y axis to the plot.\n",
    "  plt.xlabel('Predicted label' +\"\\n\\nScores\\n\" +total_score, fontsize=20)  # adding a x axis to the plot\n",
    "  plt.show()  # showing the plot\n",
    "    \n",
    "  result_list = train_accuracy,test_accuracy , precision, recall, f1_score  # returning the results\n",
    "\n",
    "  \n",
    "\n",
    "  return result_list  # returns the results from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274dac67",
   "metadata": {},
   "source": [
    "# Feature Scaling and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6542b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurescaling(Scaler, X_train, X_test, y_train, y_test, Modelandprams ,Modelname):\n",
    "    \n",
    "    sucidedataframe.info()  # checking Basic information on the dataframe being procesed.\n",
    "    \n",
    "    sc = Scaler # creating an instance of the object.\n",
    "    \n",
    "    print(\"Before scaling:\\nX_test \", X_test,\"\\n\\nX_train \", X_train)  # printing the sets before feature scaling.\n",
    "\n",
    "    X_train[:, 55:] = sc.fit_transform(X_train[:, 55:])  # Scaling x_train\n",
    "    X_test[:,55:] = sc.transform(X_test[:, 55:])  # Scaling y_train\n",
    "    \n",
    "    print(\"After scaling:\\nX_test \", X_test,\"\\n\\nX_train \", X_train)  # printing the sets after feature scaling.\n",
    "    print(\"\\nThe result of the model\")  \n",
    "    Classifier_function(Modelandprams , X_train, y_train,X_test, y_test, Modelname)  \n",
    "    # Performs traing, testing prediction.\n",
    "    # performs precision, recall, f1-score and support prediction\n",
    "    # plots a confusion matrix\n",
    "    # returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88ca26",
   "metadata": {},
   "source": [
    "# Sub function to preform Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd20d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grid_search_fun(typeofmodelandprams, dict_prams, crossval, X, y):  # Function takes in the model type,\n",
    "                                                           # number of crossvalidation sand X and y values as hyperparameters.\n",
    "\n",
    "    model = typeofmodelandprams  # creating an instance of the object.\n",
    "    parameters = [dict_prams]  # hyper parameters for the grid search\n",
    "    grid_search = GridSearchCV(estimator = model,  # model\n",
    "                           param_grid = parameters,  # hyper paramaters \n",
    "                           scoring = 'accuracy',  # score measurement\n",
    "                           cv = crossval, # number of cross validations \n",
    "                           n_jobs = -1, return_train_score=False)  # selecting all possible paramaters to go \n",
    "    # through to get the best model possible # train score is false as it can be computationaly expensive. \n",
    "    # without storing the traning score the grd search is fater\n",
    "    grid_search.fit(X, y)  # applying the search on our model.\n",
    "    #print(pd.DataFrame(grid_search.cv_results_)[[\"mean_test_score\",\"params\"]])\n",
    "    print(pd.DataFrame(grid_search.cv_results_)) # to print the whole result\n",
    "\n",
    "    best_accuracy = grid_search.best_score_  # the best accuracy \n",
    "    best_parameters = grid_search.best_params_  # the best paramaters that gave the best accurecy\n",
    "    print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))  # printing best accuracy\n",
    "    print(\"Best Parameters:\", best_parameters)  # printing the best parameters\n",
    "    \n",
    "\n",
    "\n",
    "    return grid_search  # returns grid search value\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26aebc",
   "metadata": {},
   "source": [
    "# Performs full grid search for KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KNN_full_grid_search(X, y):  # Performs grid search.\n",
    "\n",
    "        # Grid Search\n",
    "        k_list = list(range(1,31))  # list from 1 - 31 (will be used as KNN's)\n",
    "        weight_list = [\"uniform\", \"distance\"]  # weights list uniform and distance\n",
    "        para_grid = dict(n_neighbors=k_list,weights=weight_list)  # adding the above lists in a dictinorr.\n",
    "\n",
    "        \n",
    "\n",
    "        grid_search = Grid_search_fun(KNeighborsClassifier(n_neighbors=k_list), para_grid, 5, X, y)  # Using the grid \n",
    "                                                                                 # search function with arguments given \n",
    "\n",
    "        grid_search.cv_results_[\"mean_test_score\"] # looking at mean test score\n",
    "\n",
    "        uniform = []  # a empty list is created\n",
    "        for i in range(0, len(grid_search.cv_results_[\"mean_test_score\"]), 2):  # getting all even number \n",
    "                                                                               # indexes using a for loop.\n",
    "\n",
    "            uniform.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the unifrom values to the\n",
    "                                                                          # varibale unifrom.\n",
    "\n",
    "        distance = []  # a empty list is created\n",
    "        for i in range(1, len(grid_search.cv_results_[\"mean_test_score\"]), 2):  # getting all odd number indexes \n",
    "                                                                               # using a for loop.\n",
    "            distance.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the distance values to the \n",
    "                                                                            # varibale unifrom.\n",
    "\n",
    "        print(\"distance \", distance)   # printing the values distace variable.\n",
    "\n",
    "        print(\"uniform \", uniform)  # printing the values uniform variable.\n",
    "        print(\"\\n\\n\\n\")\n",
    "\n",
    "        plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "        plt.title(\"Grid Search Hyper parameter Comparison\",fontsize=25, color=\"blue\")  # setting the plot title.\n",
    "        plt.plot(k_list,uniform , \"--\", marker = \"o\", label=\"weights uniform\", color=\"red\")  # setting the uniform \n",
    "                                                      # variables values to the plot on the y axis and K_list  on the x axis.\n",
    "        plt.plot(k_list,distance ,\":\", marker = \"*\", label=\"weights distant\", color=\"blue\")  # setting the distant \n",
    "                                                         # variables values to the plot on the y axis and K_list  on the x axis.\n",
    "        plt.xlabel(\"Number of nearest neighbours\",fontsize=20)  # Setting the x label.\n",
    "        plt.ylabel(\"Avarage CV Score\",fontsize=20)  # setting the y label.\n",
    "        plt.legend(loc='lower left')  # setting the legend.\n",
    "        plt.grid()  # setting a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91278327",
   "metadata": {},
   "source": [
    "# sub function to preform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_search_fun(typeofmodelandprams, dict_prams,crossval, X, y):  # Function takes in the model type, \n",
    "                                                            # number of crossvalidation sand X and y values as hyperparameters.\n",
    "\n",
    "    model = typeofmodelandprams  # creating an instance of the object.\n",
    "    parameters = [dict_prams]  # hyper parameters for the random search \n",
    "    rand_search = RandomizedSearchCV(\n",
    "                           model,\n",
    "        #estimator = model,  # model\n",
    "                           #param_distributions = parameters,  # hyper paramaters \n",
    "                           parameters,\n",
    "                           scoring = 'accuracy',  # score measurement\n",
    "                           cv = crossval, # number of cross validations \n",
    "                           n_jobs = -1, # selecting all possible paramaters to go through to get the best model possible \n",
    "                           return_train_score=False, # train score is false as it can be computationaly \n",
    "                                                  # expensive. without storing the traning score the grd search is fater\n",
    "                           n_iter=10,  # setting the number of iterations\n",
    "                           random_state=5)  \n",
    "    rand_search.fit(X, y)  # applying the search on our model.\n",
    "    #print(pd.DataFrame(rand_search.cv_results_)[[\"mean_test_score\",\"params\"]])\n",
    "    print(pd.DataFrame(rand_search.cv_results_)) # to print the whole result\n",
    "\n",
    "    best_accuracy = rand_search.best_score_  # the best accuracy \n",
    "    best_parameters = rand_search.best_params_  # the best paramaters that gave the best accurecy\n",
    "    print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))  # printing best accuracy\n",
    "    print(\"Best Parameters:\", best_parameters)  # printing the best parameters\n",
    "    \n",
    "    print(parameters)  # prininting the parameters \n",
    "\n",
    "\n",
    "    return rand_search  # return random search value.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10e3e8",
   "metadata": {},
   "source": [
    "# Performs full Random Search on KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10de09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_full_rand_search(X, y):  # performs randomized search\n",
    "\n",
    "    # Random search \n",
    "\n",
    "\n",
    "    k_list = list(range(1,31))  # list from 1 - 31 (will be used as KNN's)\n",
    "    weight_list = [\"uniform\"]  # weights list uniform and distance\n",
    "    para_rand = dict(n_neighbors=k_list,weights=weight_list)  # adding the above lists in a dictinorr.\n",
    "    rand_search = rand_search_fun(KNeighborsClassifier(), para_rand, 5, X, y)  # Using the grid search gunction with\n",
    "                                                                                                   # arguments given \n",
    "\n",
    "    uniform = []  # creating a empty list\n",
    "    k_list1 = []  # creating a empty list\n",
    "    for i in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                                      # the mean_test_score\n",
    "\n",
    "            uniform.append(rand_search.cv_results_[\"mean_test_score\"][i])  # appending the uniform values ot the \n",
    "                                                                           # uniform variable.\n",
    "            k_list1.append(rand_search.cv_results_[\"param_n_neighbors\"][i])  # appedning the KNN's to the K_list1.\n",
    "\n",
    "    sorted_uniform = []  # creating a empty list\n",
    "    sorted_list1 = k_list1.copy()  # creating a copy of the K_list1 variables values.\n",
    "    sorted_list1.sort()   # sorting the KNNs\n",
    "    for i in range(len(sorted_list1)):  # Looping through the lenght of the sorted_list1 variable.\n",
    "        for j in range(len(k_list1)):  # Looping through the lenght of the K_list1 variable.\n",
    "            if sorted_list1[i] == k_list1[j]:  # checking that if the values of sorted_list1[i] is equal to k_list1[j]\n",
    "                sorted_uniform.append(uniform[j])  # appeding the unifrom[j] values to the sorted_uniform list.\n",
    "\n",
    "    k_list = list(range(1,31))  # list from 1 - 31 (will be used as KNN's)\n",
    "    weight_list = [\"distance\"]  # weights list distance\n",
    "    para_rand = dict(n_neighbors=k_list,weights=weight_list)  # adding the above lists in a dictinory.\n",
    "\n",
    "    rand_search = rand_search_fun(KNeighborsClassifier(), para_rand, 5, X, y)  # Using the grid search gunction with \n",
    "                                                                              # arguments given \n",
    "\n",
    "    uniform = []  # creating a empty list\n",
    "    k_list1 = []  # creating a empty list\n",
    "    for i in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                                      # the mean_test_score\n",
    "\n",
    "            uniform.append(rand_search.cv_results_[\"mean_test_score\"][i])  # appending the uniform values ot the \n",
    "                                                                          # uniform variable.\n",
    "            k_list1.append(rand_search.cv_results_[\"param_n_neighbors\"][i])  # appedning the KNN's to the K_list1.\n",
    "\n",
    "    distance = []  # creating a empty list\n",
    "    k_list2 = []  # creating a empty list\n",
    "    for i in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                                      # the mean_test_score\n",
    "            distance.append(rand_search.cv_results_[\"mean_test_score\"][i])  # appending the distance values ot the \n",
    "                                                                           # distance variable.\n",
    "            k_list2.append(rand_search.cv_results_[\"param_n_neighbors\"][i])  # appedning the KNN's to the K_list2.\n",
    "\n",
    "    sorted_distance = []  # creating a empty list\n",
    "    sorted_list2 = k_list2.copy()   # creating a copy of the K_list2 variables values.\n",
    "    sorted_list2.sort()  # sorting the KNNs\n",
    "    for i in range(len(sorted_list2)):  # Looping through the lenght of the sorted_list2 variable.\n",
    "        for j in range(len(k_list2)):  # Looping through the lenght of the K_list2 variable.\n",
    "            if sorted_list2[i] == k_list2[j]:  # checking that if the values of sorted_list2[i] equal  k_list2[j]\n",
    "                sorted_distance.append(distance[j])  # appeding the unifrom[j] values to the sorted_uniform list.\n",
    "\n",
    "    k_list1  # checking out put of  the given variables values \n",
    "\n",
    "    sorted_list1  # checking out put of  the given variables values \n",
    "\n",
    "    k_list2  # checking out put of  the given variables values  \n",
    "\n",
    "    sorted_list2  # checking out put of  the given variables values \n",
    "\n",
    "    uniform  # checking out put of  the given variables values \n",
    "\n",
    "    sorted_uniform  # checking out put of  the given variables values  \n",
    "\n",
    "    distance  # checking out put of  the given variables values  \n",
    "\n",
    "    sorted_distance  # checking out put of  the given variables values \n",
    "\n",
    "    plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "    plt.title(\"Random Search Hyper parameter Comparison\",fontsize=25, color=\"blue\")  # setting the plot title.\n",
    "    plt.plot(sorted_list1,sorted_uniform , \"--\",marker = \"o\", label=\"weights uniform\", color=\"red\")  # setting the \n",
    "                                                                                                     # uniform variables \n",
    "                                                                # values to the plot on the y axis and K_list  on the x axis.\n",
    "    plt.plot(sorted_list2,sorted_distance , \":\",marker = \"*\", label=\"weights distant\", color=\"blue\")  # setting the distant \n",
    "                                                            # variables values to the plot on the y axis and K_list  \n",
    "                                                           # on the x axis.\n",
    "    plt.xlabel(\"Number of nearest neighbours\", fontsize=20)  # Setting the x label.\n",
    "    plt.ylabel(\"Avarage CV Score\", fontsize=20)  # setting the y label.\n",
    "    plt.legend(loc='upper left')   # setting the legend.\n",
    "    plt.grid()  # setting a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f92400",
   "metadata": {},
   "source": [
    "## k-fold cross-validation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_NN_plot_Values(X,y):  # Values required for plotting\n",
    "    ave_scores = []  # Creating a empty list\n",
    "    k_list = k_list = list(range(1,50))  # Setting the values for the K_list  variable.\n",
    "    for k in k_list:  # looping through each value in the k_list variable\n",
    "        model = KNeighborsClassifier(n_neighbors = k)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5,scoring=\"accuracy\")  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    print(\"ave scores \", ave_scores)  # printing the average score of the model\n",
    "\n",
    "    \n",
    "    plt.title(\"Best KNN Selection\",fontsize=18)  # Displays plot title\n",
    "    plt.plot(k_list, ave_scores)  # Displays description of the plots x and y labels.\n",
    "    plt.xlabel(\"Number of nearest neighbours\")  # Displays the x axis for the plot\n",
    "    plt.ylabel(\"Average CV model accuracy\")  # Displays the y axis for the plot\n",
    "    plt.legend([\"KNN\"], loc=\"lower left\")  # adds a legend to the plot.\n",
    "    plt.grid()  # adds a gird to the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f1855",
   "metadata": {},
   "source": [
    "## k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd677ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalscore(model, X, y, cv_val):  # function to perform cross validation with model X, y and cv_val as parameters\n",
    "    score = cross_val_score(estimator = model, X = X, y = y, cv = cv_val)   # performs different tests to get best accurecy.\n",
    "    print(\"Accuracy: {:.2f} %\".format(score.mean()*100))  # accuracy printed.\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(score.std()*100))  # standard deveation printed (std -avarage or std+ avarage )\n",
    "    return (\"Accuracy: {:.2f} %\".format(score.mean()*100))  # Accuracy is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d7ee1",
   "metadata": {},
   "source": [
    "# X and y un_edited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d43b7",
   "metadata": {},
   "source": [
    "## Plotting the KNN's with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NN_plot_Values(X,y)  # PLots KNN Cross Val score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7709ecd",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b90cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors=20, weights=\"uniform\"), X, y, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7aa13",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b01ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_full_grid_search(X, y)  # performs grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685b6c3",
   "metadata": {},
   "source": [
    "## Random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f685d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_full_rand_search(X, y)  # performs random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff361c84",
   "metadata": {},
   "source": [
    "## Checking predicted/actual results\n",
    "## Checking testing and traning scores\n",
    "## Checking Actual values classified correctly and wrongly.\n",
    "## Checking accuracy, precision, recall and f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1186fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Classifier_function(KNeighborsClassifier(n_neighbors=20,weights=\"uniform\"), X_train, y_train,X_test, y_test, \"KNN Model\")  \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ded6a1",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results after feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1902add",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(StandardScaler(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "\n",
    "# performs standard scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cbb8b9",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aacef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b63b08",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(RobustScaler(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "# performs robust scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b56934",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcfb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(Normalizer(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "# Performs normalization scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2884a2a",
   "metadata": {},
   "source": [
    "# Best KNN model with the highest overall score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18d356",
   "metadata": {},
   "source": [
    "## Plotting the KNN's with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c439f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NN_plot_Values(X_over,y_over)  # PLots KNN Cross Val score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995d66c",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd90c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors=1), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419518b",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b62ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_full_grid_search(X_over, y_over)  # performs grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9089ede",
   "metadata": {},
   "source": [
    "## Random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_full_rand_search(X_over, y_over)  # performs random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be6cfe",
   "metadata": {},
   "source": [
    "## Checking predicted/actual results\n",
    "## Checking testing and traning scores\n",
    "## Checking Actual values classified correctly and wrongly.\n",
    "## Checking accuracy, precision, recall and f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68632cd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(KNeighborsClassifier(n_neighbors=1,weights=\"uniform\"), X_train_over, y_train_over, X_test_over, y_test_over, \"KNN Model\")  \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577b595",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5988127",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(StandardScaler(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "\n",
    "# performs standard scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da765b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015891",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37401f12",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29422ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(RobustScaler(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "# performs robust scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5f6e5",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf773741",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurescaling(Normalizer(), X_train, X_test, y_train, y_test,\\\n",
    "               KNeighborsClassifier(n_neighbors=20,weights=\"uniform\") ,\"KNN Model\")\n",
    "# Performs normalization scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e2863",
   "metadata": {},
   "source": [
    "#  X and y obtained by using Corelation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6761fb7",
   "metadata": {},
   "source": [
    "## Plotting the KNN's with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NN_plot_Values(X2,y)  # PLots KNN Cross Val score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018ec3f",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors=23), X2, y, 10)  # Performs cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32098187",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_full_grid_search(X2, y)  # performs grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a691fa",
   "metadata": {},
   "source": [
    "## Random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_full_rand_search(X2, y)  # performs random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009fb8e",
   "metadata": {},
   "source": [
    "## Checking predicted/actual results\n",
    "## Checking testing and traning scores\n",
    "## Checking Actual values classified correctly and wrongly.\n",
    "## Checking accuracy, precision, recall and f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2437ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(KNeighborsClassifier(n_neighbors=23,weights=\"uniform\"), X2_train, y2_train,X2_test, y2_test, \"KNN Model\")\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix.info()  # information on the confusion matrix"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
