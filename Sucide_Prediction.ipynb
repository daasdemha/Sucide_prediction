{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b995cfa",
   "metadata": {},
   "source": [
    "## Downloading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a7d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install imbalanced-learn # used to install imbalanced learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbed2e0",
   "metadata": {},
   "source": [
    "# Make sure the version of anaconda is the latest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63095a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn  # importing sklearn\n",
    "print(sklearn.__version__)  # printing sklearn version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46355d5",
   "metadata": {},
   "source": [
    "### Importing the relevent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e9a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Allows us to work with arrays.\n",
    "import pandas as pd  # importing pandasâ€™ library for use. Allows us to import data set and manipulate it.\n",
    "\n",
    "import seaborn as sns  # Allows to polt beautiful plots.\n",
    "import matplotlib.pyplot as plt  # Allows working with plots.\n",
    "from mpl_toolkits import mplot3d  # plotting 3d plots\n",
    "\n",
    "from sklearn.compose import ColumnTransformer  # helps with encoding.\n",
    "from sklearn.preprocessing import OneHotEncoder  # Does onehotencode.\n",
    "from sklearn.preprocessing import LabelEncoder   # Does 1 and 0 encoding.\n",
    "from sklearn.model_selection import train_test_split  # Splits dataset into test set and traning set. \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer  # Perform the feature scaling.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, multilabel_confusion_matrix  # creates a \n",
    "                                                                            # confusion matrix  # creates a confusion matrix\n",
    "from sklearn.metrics import accuracy_score  # Returns accury score of a model.\n",
    "from collections import Counter  # Allows the counting the items in an iterable list.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  # Performs logistic regression.\n",
    "from sklearn.neighbors import KNeighborsClassifier  # applies  K Neariesst Neighobour.\n",
    "from sklearn.neural_network import MLPClassifier  # applies Multilayer Perceptrons neural network\n",
    "from sklearn.impute import KNNImputer  # imputes missing values using KNN.\n",
    "from sklearn.naive_bayes import GaussianNB  # applies  naive_bayes gaussianNB.\n",
    "from sklearn.tree import DecisionTreeClassifier  # applies  decision tree classification model.\n",
    "from sklearn.ensemble import RandomForestClassifier  # applies random forest classification.\n",
    "from sklearn.decomposition import PCA  # applies PCA\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  # performs cross validation. Helps in model selection.\n",
    "from sklearn.model_selection import GridSearchCV  # helps select the best hyper parameters\n",
    "from imblearn.over_sampling import RandomOverSampler  # Uses over sampling techniques to Sample the data correctly.\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, roc_auc_score, f1_score \n",
    "                                                                                 # Allows the usage of a classification report\n",
    "from sklearn.metrics import precision_recall_fscore_support  # gives precison, recall, f1 score, and support\n",
    "from sklearn.model_selection import RandomizedSearchCV  # performs randomized search cv\n",
    "\n",
    "import warnings  # allows to ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignores warnings\n",
    "\n",
    "#%matplotlib inline  # helps in showing plots on the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c5c32",
   "metadata": {},
   "source": [
    "### Importing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985866e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe = pd.read_csv(\"suicidedataextrafestures.csv\")  # opens csv files and assighns them to a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d2088",
   "metadata": {},
   "source": [
    "### Checking the data from the dataframe before pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb046731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head(1)  # Taking a look at the dataframe the first elements of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b27895",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da515d3",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953dfc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Below relevent data is selected that will be used in this project.\n",
    "sucidedataframe = sucidedataframe[[\"country\", \"age\" ,\"sex\", \"population\",  \\\n",
    "\"Individuals using the Internet (% of population)\", \"Labor force, total\", \\\n",
    "\"Mobile cellular subscriptions (per 100 people)\", \"GDPpyear\",\"GDPpcapital\",\"Expense (% of GDP)\",\\\n",
    "\"Physicians (per 1,000 people)\",\"Refugee population by country or territory of origin\" ,\"suicidesper100k\"]]## 1. Data \n",
    "                                                                                                          # pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92fd7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head(5)  # out puts data from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a506c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Below the col names are renamed.\n",
    "sucidedataframe = sucidedataframe.set_axis([\"Country\", \"Age\", \"Gender\", \"Population\", \\\n",
    "\"Internet_Usage_per_percent_Population\", \"Total_Labour_force\", \"Cellular_subscriptions_per_100_people\", \\\n",
    "\"GDPpyear\",\"GDPpcapital\",\"Expense_percent_of_GDP)\",\\\n",
    "\"Physicians_per_1,000_people)\",\"Refugee_population_by_country_or_territory_of_origin\" ,\"Suicidesper100k\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6536d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.columns  # The columns of the dataframe are viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72482132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.shape  # The Entries and the columns of the dataframe are viewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b358d",
   "metadata": {},
   "source": [
    "### Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0a58b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(sucidedataframe.isnull())  # shows null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c7bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.isnull().sum()  # Checking the dataframe for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef3824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking basic information on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19484c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['Internet_Usage_per_percent_Population'] = df['DataFrame Column'].fillna(mean(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531a865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sucidedataframe.Internet_Usage_per_percent_Population))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aca313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sucidedataframe.Refugee_population_by_country_or_territory_of_origin))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69de18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sucidedataframe[\"Expense_percent_of_GDP)\"]))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e90761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sucidedataframe[\"Physicians_per_1,000_people)\"]))  # printing lenghth of the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0332511",
   "metadata": {},
   "source": [
    "#  Function to replace missing values Using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026041b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def missng_values_filler_knn(missingdataframevalue,colname):  # function replaces missing values using KNN's. function \n",
    "                                                              # name specified and paramaters given\n",
    "    columntobereplaced = missingdataframevalue.to_numpy()   # The column to be replaced is stored in a variable.\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")  # creating instance of the object.\n",
    "    replaced = imputer.fit_transform(columntobereplaced)  # fitting the model and replaing missing values\n",
    "                                                                       \n",
    "    print(len(replaced))  # printing replaced lenght\n",
    "    dataframe=pd.DataFrame(replaced, columns=colname)  # adding replaced values in a dataframe column and giving the column a \n",
    "                                                      # name.\n",
    "    print(\"null values \", dataframe.isnull().sum()) # Checking the dataframe for null values.\n",
    "    print(dataframe.head(5))  # printing head of new data frame\n",
    "    return dataframe  # returning the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7f49b",
   "metadata": {},
   "source": [
    "# Replacing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e8391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe[[\"Internet_Usage_per_percent_Population\"]] = \\\n",
    "missng_values_filler_knn(sucidedataframe[[\"Internet_Usage_per_percent_Population\"]], [\"Internet_Usage_per_percent_Population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723848e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing null values using KNN function\n",
    "sucidedataframe[[\"Expense_percent_of_GDP)\"]] = \\\n",
    "missng_values_filler_knn(sucidedataframe[[\"Expense_percent_of_GDP)\"]], [\"Expense_percent_of_GDP)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0d634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing null values using KNN function\n",
    "sucidedataframe[[\"Refugee_population_by_country_or_territory_of_origin\"]] = \\\n",
    "missng_values_filler_knn(sucidedataframe[[\"Refugee_population_by_country_or_territory_of_origin\"]],\\\n",
    "                         [\"Refugee_population_by_country_or_territory_of_origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83e64e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing null values using KNN function\n",
    "sucidedataframe[[\"Physicians_per_1,000_people)\"]] = \\\n",
    "missng_values_filler_knn(sucidedataframe[[\"Physicians_per_1,000_people)\"]],[\"Physicians_per_1,000_people)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d81c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.isnull().sum()  # Checking the dataframe for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fbfce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.dropna() # droping all rows with at least one null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f9653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sucidedataframe.isnull().sum()  # Checking the dataframe for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e94c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.shape  # The Entries and the columns of the dataframe are viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2c581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbedef1",
   "metadata": {},
   "source": [
    "# Reseting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc5c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.reset_index(drop=True, inplace=True)  # reseting index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14a5e9",
   "metadata": {},
   "source": [
    "### Looking at outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4154c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def outliers_check(fig,columnnametocheck):   # function with parameters given.\n",
    "    \"\"\" \n",
    "    The outlier_check fuction plots outliers for the sucidedataframe.\n",
    "    \n",
    "    The first parameter fig takes a number as argument which is the number of the figure bening plotted.\n",
    "    \n",
    "    \n",
    "    The second parameter columnnametocheck takes a column anme from sucidedataframe to plot its outliers.\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure(fig)  # number of the figure being plotted.\n",
    "    plt.title(\"Outliers\",fontsize=18)  # Displays plot title\n",
    "    plt.boxplot(sucidedataframe[[columnnametocheck]])  # Displays description of the plots x and y labels.\n",
    "    plt.xlabel(columnnametocheck)  # Displays the x axis for the plot\n",
    "    plt.ylabel(columnnametocheck)  # Displays the y axis for the plot.\n",
    "    plt.grid()  # adds a gird to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45b5a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_values_list = [\"Population\",\"Internet_Usage_per_percent_Population\", \"Total_Labour_force\",\\\n",
    "\"Cellular_subscriptions_per_100_people\" , \"GDPpyear\", \"GDPpcapital\", \"Expense_percent_of_GDP)\", \"Physicians_per_1,000_people)\",\\\n",
    "                     \"Refugee_population_by_country_or_territory_of_origin\",  \"Suicidesper100k\"] # a list of column names in \n",
    "                                                                                         # sucidedataframe to use for plotting.\n",
    "for i in range(len(plot_values_list)):  # looping in a range of the length of plot_values_list.\n",
    "    outliers_check(i+1,plot_values_list[i])  # Arguemnts given to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()  # number of the figure being plotted.\n",
    "plt.style.use('seaborn-white')  # style to use for seaborn.\n",
    "sns.catplot(x='Gender', y=\"Suicidesper100k\", col=\"Age\", col_wrap=3, sharey=True, \\\n",
    "            data=sucidedataframe, alpha=0.5, palette = 'hot')  # plots gender and Age in relationship with columnnametocheck.\n",
    "plt.xticks(rotation = 90)  # rotates plot to 90 degree\n",
    "plt.show()  # shows plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()  # number of the figure being plotted.\n",
    "plt.style.use('seaborn-white')  # style to use for seaborn.\n",
    "sns.catplot(x='Gender', y=\"Population\", col=\"Age\", col_wrap=3, sharey=True, \\\n",
    "            data=sucidedataframe, alpha=0.5, palette = 'hot')  # plots gender and Age in relationship with columnnametocheck.\n",
    "plt.xticks(rotation = 90)  # rotates plot to 90 degree\n",
    "plt.show()  # shows plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3fbf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relationsucide100kwithage(fig,columnnametocheck):  # function with parameters given.\n",
    "    \n",
    "    \"\"\" \n",
    "    The relationsucide100kwithage plots the relationship between a given column from the sucidedatafame with the \n",
    "    Suicidesper100k, Gender and Age column form the same dataframe.\n",
    "    \n",
    "    The first parameter fig takes a number as argument which is the number of the figure bening plotted.\n",
    "    \n",
    "    \n",
    "    The second parameter columnnametocheck takes a column name from sucidedataframe to check its relationship with the \n",
    "    Suicidesper100k, Gender and Age column form the same dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    plt.figure(fig)   # number of the figure being plotted.\n",
    "    My_plot_object = sns.FacetGrid(sucidedataframe , row = 'Gender',col = 'Age',margin_titles=True)\n",
    "    My_plot_object.map(plt.scatter,\"Suicidesper100k\",columnnametocheck,edgecolor = 'w')  # plots \"Suicidesper100k\"  column in \n",
    "                                                             # relation to columnnametocheck from sucidedataframe.\n",
    "    plt.show()  # shows plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c8484",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_values_list = [\"Population\", \"GDPpyear\", \"Refugee_population_by_country_or_territory_of_origin\"] # a list of \n",
    "                                                                                        # column names in \n",
    "                                                                                         # sucidedataframe to use for plotting.\n",
    "for i in range(len(plot_values_list)):  # looping in a range of the length of plot_values_list.\n",
    "    relationsucide100kwithage(i+1,plot_values_list[i])   # Arguemnts given to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1ce02",
   "metadata": {},
   "source": [
    "# Function to perform OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5784c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encodingoh(required_column,dropped_column,column_rename):  # function to perform the one hot encoding with parameters given.\n",
    "    \n",
    "    \"\"\"\n",
    "    encodingoh fuction perfoms OneHotEncoding on a given dataset column.\n",
    "    \n",
    "    The first parameter required_column is the column to be OneHotEncoded.\n",
    "    \n",
    "    The second parameter dropped_column checks if the is a column to be dropped when OneHotEncoding.\n",
    "    for example the arguemnt None drops no columns.\n",
    "                the argement \"first\" drops the fist column when OneHotEncoding.\n",
    "                \n",
    "    The Third parameter column_rename is the new names of the colums after OneHotEncoding\n",
    "    \n",
    "    The encodingoh function returns a one hot encoded dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    oh = OneHotEncoder(drop=dropped_column,dtype=np.int)  # creates the instace of the object.\n",
    "    newdf = required_column  # creates a new data frame from the column to be one hot encoded\n",
    "    newdf = oh.fit_transform(newdf).toarray()  # one hot enocdes the new dataframe as a array\n",
    "    newdf = pd.DataFrame(newdf)  # converts the newly created array to a dataframe.\n",
    "    newdf.columns = column_rename  # renames the newly encoded column\n",
    "    print(newdf.head(5))  # outputs the head of the dataframe.\n",
    "    return newdf  # returns the one hot encoded data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439de35b",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778e083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.nunique()  # outputs unique values in each column in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c425de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.duplicated().sum()  # gives the sum of duplicate dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16a634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Gender'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05679549",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Country'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb568e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head(1)  # outputs the head of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfef85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Age'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1656f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.index = pd.RangeIndex(len(sucidedataframe.index))  # outputs indext of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9602b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c742a",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53804a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Gender'], aggfunc='size'))  # prints the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472836b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Age'], aggfunc='size'))  # prints the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bae9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  one hot enocdes the column using the created function.\n",
    "age = encodingoh(sucidedataframe[[\"Age\"]], None, ['15-24 years',\"25-34 years\", \"35-54 years\", \\\n",
    "                                                  \"5-14 years\", \"55-74 years\", \"75+ years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04e6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  one hot enocdes the column using the created function.\n",
    "gender = encodingoh(sucidedataframe[[\"Gender\"]], \"first\", [\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88555276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.drop('Age', 1)  # column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5fe188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.drop('Gender', 1)   # column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51efce47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head(5)  # dataframe head is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f5cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe = pd.concat([ gender,sucidedataframe],axis=1)  # column is concatanated to dataframe\n",
    "sucidedataframe.head()  # fisrt elements of the dataframe are outptted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e37f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sucidedataframe = pd.concat([age,sucidedataframe],axis=1)  # column is concatanated to dataframe\n",
    "sucidedataframe  # fisrt elements of the dataframe are outptted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe69b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Gender'], aggfunc='size'))   # prints the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d351b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['15-24 years'], aggfunc='size'))  # counts duplicates in the selected \n",
    "                                                                             # dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aced977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"25-34 years\"], aggfunc='size'))  # counts duplicates in the selected \n",
    "                                                                             # dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb123e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"35-54 years\"], aggfunc='size'))  # counts duplicates in the \n",
    "                                                                        # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fd09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"5-14 years\"], aggfunc='size'))  # counts duplicates in the\n",
    "                                                                            # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24042f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"55-74 years\"], aggfunc='size'))  # counts duplicates in the \n",
    "                                                                            # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd610a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=[\"75+ years\"], aggfunc='size'))  # counts duplicates in the \n",
    "                                                                        # selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d5615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head()  # the first elements of the data frame are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373eceb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.describe().round()  # Shows the count, mean, std, min, 25%, 50%, 75% and \n",
    "                                    # max of a datframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94464e04",
   "metadata": {},
   "source": [
    "# Checking and selecting higly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec4822",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))  # sets the size of the matrix\n",
    "correlation_matrix = sucidedataframe.corr().round(2)  # creates the correlation matrix\n",
    "sns.heatmap(data = correlation_matrix, annot = True)  # shows correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497f3d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix = sucidedataframe[[ \"Gender\", \"5-14 years\", \"15-24 years\", \"75+ years\"]]  # higher correlated \n",
    "                                                                                                       # features are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e7dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix.head()  # first elements of the dataframe are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d5c1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count duplicates function learned from: https://datatofish.com/count-duplicates-pandas/\n",
    "sucidedataframe.pivot_table(columns=['Country'], aggfunc='size')  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b843e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "each_country = np.unique(sucidedataframe[[\"Country\"]].values) # unique country rows are selected.\n",
    "each_country  # array is outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454c2a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Country = encodingoh(sucidedataframe[[\"Country\"]], None, each_country)  # each country is one hot encoded at a time.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8eafd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe = pd.concat([Country,sucidedataframe],axis=1)  # each new country is concatanated to original data frame.\n",
    "sucidedataframe.head() # first elements of the data frame are out putted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c6dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix = pd.concat([Country,Features_after_corelation_matrix],axis=1)  # each new country is \n",
    "                                                                     # concatanated to highly correlate data frame.\n",
    "Features_after_corelation_matrix.head()   # first elements of the data frame are out putted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40411854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.columns)  # columns of the data frame are printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbcfa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe = sucidedataframe.drop('Country', 1)  # country column is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d13c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.columns)  # columns of the data frame are printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0330f",
   "metadata": {},
   "source": [
    "# Making lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af1105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.describe().round()  # Shows the count, mean, std, min, 25%, 50%, 75% and \n",
    "                                    # max of a datframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9527adea",
   "metadata": {},
   "source": [
    "#  Selecting the values for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919eec38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"max :   \", 178 )  # prints the given input.\n",
    "print(\"high :  \", round(178 / 2))  # prints the given input.\n",
    "print(\"medium :\", round(89 / 2))  # prints the given input.\n",
    "print(\"low :   \", round(44 / 2))  # prints the given input.\n",
    "print(\"min :   \", round(22 / 2))  # prints the given input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858d438",
   "metadata": {},
   "source": [
    "# Coverting the values to catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78341c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] < 11), \"Suicidesper100k\"] = 1 # Encoding values below 11 as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6a922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 11) & (sucidedataframe[\"Suicidesper100k\"] < 22),\\\n",
    "                    \"Suicidesper100k\"] = 2  \n",
    "# Encoding values aboveor equal to 11 as and below 22 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3b170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 22) & (sucidedataframe[\"Suicidesper100k\"] < 44),\\\n",
    "                    \"Suicidesper100k\"] = 3 \n",
    "# Encoding values equal to and above 22 and below 44 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b92351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 44) & (sucidedataframe[\"Suicidesper100k\"] < 89),\\\n",
    "                    \"Suicidesper100k\"] = 4  \n",
    "# Encoding values above or equal to 44 as and below 89 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a484a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.loc[(sucidedataframe[\"Suicidesper100k\"] >= 89) & (sucidedataframe[\"Suicidesper100k\"] <= 178), \\\n",
    "                    \"Suicidesper100k\"] = 5 \n",
    "# Encoding values above or equal to 89 as and below 178 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889c0de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469d228",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980cba52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()  # creating the instance of the object.\n",
    "sucidedataframe.Suicidesper100k = le.fit_transform(sucidedataframe.Suicidesper100k)  # label encoing the require dcolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6863ad8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111837e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sucidedataframe.pivot_table(columns=['Suicidesper100k'], aggfunc='size'))  # counts duplicates in the selected \n",
    "                                                                                # dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b383abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "9264 + 2850 + 2177 + 678 + 141  # calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396594d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head()  # outputting dataframe head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfafc14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one = str(round(100 * (9264/15110),2)) + \"%\"   # percentage of the value is checked from label column.\n",
    "two  = str(round(100 * (2850/15110),2)) + \"%\"  # percentage of the value is checked from label column.\n",
    "three = str(round(100 * (2177/15110),2)) + \"%\"  # percentage of the value is checked from label column.\n",
    "four = str(round(100 * (678/15110),2)) + \"%\"  # percentage of the value is checked from label column.\n",
    "five = str(round(100 * (141/15110),2)) + \"%\"  # percentage of the value is checked from label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b25d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"1 is represented \", one, \"\\n2 is represented \", two, \"\\n3 is represented \", three, \"\\n4 is represented \", four, \"\\n5 is represented \", five)\n",
    "# percentage of the value is printed of label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b0169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar([1,2,3,4,5],[9262, 2850, 2177, 678, 141])  # bar chart is outputted to show the difference in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3732425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head()  # dataframe head is outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d914b3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sucidedataframe.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5602f",
   "metadata": {},
   "source": [
    "### selecting X and Y values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a48807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sucidedataframe.head(1)  # the fisrt elements of the data frame are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b82ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Features_after_corelation_matrix.head(1)  # the fisrt elements of the data frame are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792900e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = sucidedataframe.iloc[:, :-1].values  # selecting the values for the X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72c6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2 = Features_after_corelation_matrix.iloc[:, :].values # selecting the \n",
    "                                                                                        # values for the X2 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34224f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = sucidedataframe.iloc[:, -1].values # selecting the values for the Y variable. # done using .to_numpy and not \n",
    "                                                       # .iloc as .to_numpy creates a horizontal bar while .iloc creates a \n",
    "                                                       # horizontal bar which will not alighn with the x values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b744e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"X \", X, \"\\n\", \"X2 \" , X2 , \"\\n\", \"y \", y)  # priting arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07f9f0",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d7e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Original dataset shape %s' % Counter(y))  # original data set rows counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df507fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)  # instance of object created.\n",
    "X_over, y_over = ros.fit_resample(X, y)  # oversampling model fitting\n",
    "print('Resampled dataset shape %s' % Counter(y_over))  # oversampled data set rows counted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f10bfe",
   "metadata": {},
   "source": [
    "# Function to check principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a9c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pcafuntion(X,pcomponents ,pcolumns, y_value, y_var, plot_labels):  # A function to perfrom PCA with paramenters given.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    The pcafunction gives the principal components of a given datafame with respect to the selected label.\n",
    "    It also plots a 2d and 3d PCA plot if the number of pca are 2 or 3 respectively.\n",
    "    \n",
    "    The first parameters X is the columns from a dataframe as a array to be converted to principal components.\n",
    "    \n",
    "    The second parameter pcomponents is the name of the principal componets that are to be added as a list.\n",
    "    For example ['principal component 1','principal component 2'].\n",
    "    \n",
    "    The third parameter y_value is the column from the dataframe to be used as the y variable.\n",
    "    For example df[[\"y_var\"]]\n",
    "    \n",
    "    The fourth parameter y_var is the name of the y column for the dataframe.\n",
    "    \n",
    "    The fifth parameter plot_labels is the legends for the plot.\n",
    "    \n",
    "    The pcafunction function returns the given dataframes required principal comonents concanated with the \n",
    "    y label as a dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Normalizing data before applying pca\n",
    "    sc = StandardScaler()  # creating an instance of the object.\n",
    "    X = sc.fit_transform(X)   # selecting vaues to perfom transformation on  \n",
    "\n",
    "    pca = PCA(n_components=pcomponents)  # selecting number of principal components\n",
    "    principalComponents = pca.fit_transform(X)  #  # selecting values to perfom transformation on  \n",
    "    principalDf = pd.DataFrame(data = principalComponents  # creating a new dataframe with principal components.\n",
    "                 , columns =pcolumns)\n",
    "    finalDf = pd.concat([principalDf, y_value], axis = 1)  # concnating principal componenets with Class.\n",
    "\n",
    "\n",
    "    missing = 0  # setting variable to 0.\n",
    "    for i in range(len(pca.explained_variance_ratio_)):  # for looping in length of the array pca.explained_variance_ratio_\n",
    "        missing = missing  + pca.explained_variance_ratio_[i]  # adding pca.explained_variance_ratio_[i] \n",
    "                                                              # varables values to missing variable\n",
    "    print(\"Total values :  \", missing, \"%\")  # total data left \n",
    "    missing = 1 - missing  # subtracting missing variables value from 1.\n",
    "    print(\"missing values :\", missing, \"%\")  # total data lost\n",
    "    \n",
    "    \n",
    "    \n",
    "    if pcomponents == 2:  # checks the number of principal components.\n",
    "        plot = sns.relplot(\n",
    "            x='principal component 1',   # selecting first princal component.\n",
    "            y='principal component 2',   # selecting second princal component.\n",
    "            hue=y_var, # sets hue to the y variable.\n",
    "            data=finalDf, # selects where to get data from.\n",
    "            facet_kws={'legend_out': False}  # helps in selecting a custom legend.\n",
    "        )  # plots a scatter plot of principal components.\n",
    "\n",
    "        plt.title('Dataset with pca')  # Title of the plot\n",
    "        # check axes and find which is have legend\n",
    "        leg = plot.axes.flat[0].get_legend()\n",
    "        new_title =y_var  # Legend title.\n",
    "        leg.set_title(new_title)  # setting title to legend.\n",
    "        leg.get_frame().set_alpha(255) # setting transparency level for legend box\n",
    "        labels = plot_labels  # label list for legend\n",
    "        for t, l in zip(plot._legend.texts, labels):  # looping through a touple.\n",
    "            t.set_text(l)  # adding label to list\n",
    "    \n",
    "    elif pcomponents == 3:  # checks the number of principal components.\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))  # setting plot size\n",
    "        ax = plt.axes(projection='3d')  # specifying that it is a 3d plot.\n",
    "        plt.title('Dataset with pca', fontsize=20)  # adding a title to the plot\n",
    "        # Data for three-dimensional scattered points\n",
    "        xdata = finalDf['principal component 1']  # selecting first princal component.\n",
    "        ydata = finalDf['principal component 2']  # selecting second princal component.\n",
    "        zdata = finalDf['principal component 3']  # selecting third princal component.\n",
    "        ax.scatter3D(xdata, ydata, zdata, c=y_value)  # plotting princhpla components\n",
    "\n",
    "        ax.set_xlabel(\"First Principal Component\",fontsize=15)  # setting label for first principal componenet.\n",
    "        ax.set_ylabel(\"Second Principal Component\",fontsize=15)  # setting label for second principal componenet.\n",
    "        ax.set_zlabel(\"Third Principal Component\",fontsize=15)  # setting label for third principal componenet.\n",
    "\n",
    "        plt.show()  # making plot visible.\n",
    "        \n",
    "    return finalDf  # returning finalDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf6de1",
   "metadata": {},
   "source": [
    "# Principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb5858",
   "metadata": {},
   "source": [
    "## Using continues variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03199c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_pca = sucidedataframe.iloc[:, 55:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87077483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pcafuntion(X_pca,2 ,['principal component 1','principal component 2'], sucidedataframe[[\"Suicidesper100k\"]], \\\n",
    "           \"Suicidesper100k\", [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4bec4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pcafuntion(X_pca,3 ,['principal component 1','principal component 2', 'principal component 3'], \\\n",
    "           sucidedataframe[[\"Suicidesper100k\"]], \"Suicidesper100k\", [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0954466a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pcom = \"principal component \"\n",
    "plist = ['principal component 1','principal component 2', 'principal component 3']\n",
    "for i in range(4,10):\n",
    "    plist.append(pcom + str(i))\n",
    "    print(\"Number of Components \", i)\n",
    "    pcafuntion(X_pca,i ,plist, sucidedataframe[[\"Suicidesper100k\"]], \"Suicidesper100k\", [1,2,3,4,5])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d46ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c5729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "717f1855",
   "metadata": {},
   "source": [
    "## k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd677ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crossvalscore(model, X, y, cv_val):  # function to perform cross validation with model X, y and cv_val as parameters\n",
    "    \"\"\"\n",
    "    The crossvalscore function prints the avarage coross validation accuracy of a model and its standard deveation.\n",
    "    \n",
    "    The first parameter model is the type of model to perform the cross validation on.\n",
    "    \n",
    "    The second parameter X is the features.\n",
    "    \n",
    "    The third parameter y is the labels.\n",
    "    \n",
    "    the foruth parameter cv_val is the number of times to cross validate the given model.\n",
    "    \n",
    "    The crossvalscore function returns the mean accuracy of the model.\n",
    "    \n",
    "    \"\"\"\n",
    "    score = cross_val_score(estimator = model, X = X, y = y, cv = cv_val, scoring = 'f1_macro')   # performs different\n",
    "                                                                                        # tests to get best accurecy.\n",
    "    print(\"f1 score: {:.2f} %\".format(score.mean()*100))  # accuracy printed.\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(score.std()*100))  # standard deveation printed (std -avarage or std+ avarage )\n",
    "    return round(score.mean(),2)*100, round(score.std(),2)*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a3b2e",
   "metadata": {},
   "source": [
    "# Evaluating different models to choose which one to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1305b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = [\"Logistc Regression\", \"KNN\", \"Naive Bayes\", \"Neural Networks\", \"Decision Tree\", \"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d869982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy_list = []  # making empty list\n",
    "std_list = []  # making empty list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73cddf",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e651cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(LogisticRegression(), X, y, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc23e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy, std = crossvalscore(LogisticRegression(), X_over, y_over, 10)  # Performs cross validation.\n",
    "Accuracy_list.append(Accuracy)  # appending to list\n",
    "std_list.append(std)  # appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbb2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(LogisticRegression(), X2, y, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61e7ac",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c2301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(), X, y, 10)  # Performs cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a19c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy, std = crossvalscore(KNeighborsClassifier(), X_over, y_over, 10)  # Performs cross validation.\n",
    "Accuracy_list.append(Accuracy)  # appending to list\n",
    "std_list.append(std)  # appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2298069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(), X2, y, 10)  # Performs cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d85f94",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7123d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(GaussianNB(), X, y, 10)  # Performs cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130a293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy, std = crossvalscore(GaussianNB(), X_over, y_over, 10)  # Performs cross validation.\n",
    "Accuracy_list.append(Accuracy)  # appending to list\n",
    "std_list.append(std)  # appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec0ea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(GaussianNB(), X2, y, 10)  # Performs cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b946842",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29001fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(MLPClassifier(), X, y, 10)  # Performs cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40acbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy, std = crossvalscore(MLPClassifier(), X_over, y_over, 10)  # Performs cross validation.\n",
    "Accuracy_list.append(Accuracy)  # appending to list\n",
    "std_list.append(std)  # appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c690b8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(MLPClassifier(), X2, y, 10)  # Performs cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf0f9d",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a3fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(DecisionTreeClassifier(), X, y, 10)  # Performs cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a0986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy, std = crossvalscore(DecisionTreeClassifier(), X_over, y_over, 10)  # Performs cross validation.\n",
    "Accuracy_list.append(Accuracy)  # appending to list\n",
    "std_list.append(std)  # appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a3fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(DecisionTreeClassifier(), X2, y, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e62a7a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3a067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(RandomForestClassifier(), X, y, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3a067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy, std = crossvalscore(RandomForestClassifier(), X_over, y_over, 10)  # Performs cross validation.\n",
    "Accuracy_list.append(Accuracy)  # appending to list\n",
    "std_list.append(std)  # appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3a067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(RandomForestClassifier(), X2, y, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc7e8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation2 = pd.DataFrame({\n",
    "    'Model':model_name,\n",
    "    'Crossvaladation f1 score':Accuracy_list,\n",
    "    'Standard deveation':std_list,\n",
    "})  # using lists to make a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d913eb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Evaluation2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ae40c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation2.sort_values(by='Crossvaladation f1 score', ascending=False) # viewing dataframe information by f1 score in decending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957de300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation2.sort_values(by='Standard deveation', ascending=True) # viewing dataframe information by recall in decending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f0bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_bar_graph(list_for_plot, list_for_plot2,Accuracy_type, colour):  # funstion with given parameters.\n",
    "    \n",
    "    \"\"\"\n",
    "    The function plot_bar_graph plots a bar graph.\n",
    "    \n",
    "    The first parameter list_for_plot is the x axis.\n",
    "    \n",
    "    The second parameter list_for_plot2 is the y axis.\n",
    "    \n",
    "    The third parameter Accuracy_type takes a string. \n",
    "    for example \"F1 score\"\n",
    "    \n",
    "    The fourth parameter colour is the color for the bar plot.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    plt.figure()  # plots figure\n",
    "    plt.figure(figsize = (15,10)) # sets the size of the plot\n",
    "    plt.title(\"Model Evaluation\",fontsize=18)  # Displays plot title\n",
    "    plt.bar(list_for_plot, list_for_plot2, color = colour)  # Displays description of the plots x and y labels.\n",
    "    plt.xlabel(\"Models\")  # Displays the x axis for the plot\n",
    "    plt.ylabel(Accuracy_type)  # Displays the y axis for the plot.\n",
    "    plt.grid()  # adds a gird to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e33232",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_bar_graph(model_name, Accuracy_list , \"f1 score\", \"red\")  # functions argents given. plots output using given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef9aeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_bar_graph(model_name, std_list , \"standard deveation\", \"blue\")  # functions argents given. plots output using given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68b6b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b43cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "510d558b",
   "metadata": {},
   "source": [
    "## Original x and y values after they have been over Sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b6f77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over, test_size = 0.2, random_state = 1)\n",
    "# test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                            # to get the best results.                                                           \n",
    "# random_state = 1         # resetting the  random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f165b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the lenghth of both test and train set to see if there equally split.\n",
    "print(\"The length of X_train_over is \",len(X_train_over), \" and the length of y_train_over is \", len(y_train_over))  \n",
    "print(\"The length of X_test_over is \",len(X_test_over), \" and the length of y_test_over is \", len(y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdac53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c09ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5295efae",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f92400",
   "metadata": {},
   "source": [
    "## k-fold cross-validation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa42a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def subplot(list_for_plot, ave_scores, hyper_pram_to_use_name):   # A function with parameters given.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    The function subplot plots a linear plot and shows the best results using two lists \n",
    "    the fist one acting as a label to the second list and the second list being scores.\n",
    "    \n",
    "    The first parameter list_for_plot is the X label.\n",
    "    \n",
    "    The second parameter ave_scores is the y label.\n",
    "    \n",
    "    The thrid paramater hyper_pram_to_use_name is the the titile for the plot.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure()  # plot a figure\n",
    "    plt.title(\"Best \" + hyper_pram_to_use_name + \" Selection\",fontsize=18)  # Displays plot title\n",
    "    plt.plot(list_for_plot, ave_scores)  # Displays description of the plots x and y labels.\n",
    "    plt.xlabel(hyper_pram_to_use_name +\" values\")  # Displays the x axis for the plot\n",
    "    plt.ylabel(\"Average CV model f1 score\")  # Displays the y axis for the plot\n",
    "    plt.legend([hyper_pram_to_use_name], loc=\"lower right\")  # adds a legend to the plot.\n",
    "    plt.grid()  # adds a gird to the plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6f50f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def K_NN_plot_Values(X,y):  # A function with parameters given.\n",
    "    \n",
    "    \"\"\"\n",
    "    The K_NN_plot_Values performs cross valadation on the KNN models all hyperparametes, prints \n",
    "    the best hyperparameters that give the best reults and plots the results\n",
    "    \n",
    "    The first parameter X takes the features.\n",
    "    \n",
    "    The first parameter y takes the lables.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    k_list = k_list = list(range(1,50))  # Setting the values for the list  variable.\n",
    "    for single_val in k_list:  # looping through each value in the k_list variable\n",
    "        model = KNeighborsClassifier(n_neighbors = single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5,scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "\n",
    "    \n",
    "    subplot(k_list, ave_scores, \"n_neighbors\") # using the function to plot x and y values.\n",
    "    \n",
    "\n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    weight_list = [\"uniform\", \"distance\"]  # weights list uniform and distance\n",
    "    for single_val in weight_list:  # looping through each value in the list variable\n",
    "        model = KNeighborsClassifier(weights = single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5,scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "\n",
    "    \n",
    "    subplot(weight_list, ave_scores, \"weights\") # using the function to plot x and y values \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    metric_list =  ['minkowski','euclidean','manhattan']  # a list of KNN metrics \n",
    "    for single_val in metric_list:  # looping through each value in the list variable\n",
    "        model = KNeighborsClassifier(metric = single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5,scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "            \n",
    "    \n",
    "    subplot(metric_list, ave_scores, \"metric\") # using the function to plot x and y values \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    algorithm_list = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    for single_val in algorithm_list:  # looping through each value in the list variable\n",
    "        model = KNeighborsClassifier(algorithm = single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5,scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "\n",
    "    subplot(algorithm_list, ave_scores, \"algorithm\") # using the function to plot x and y values \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    leaf_size_list = list(range(1,30)) # a list of KNN metrics \n",
    "    for single_val in leaf_size_list:  # looping through each value in the list variable\n",
    "        model = KNeighborsClassifier(algorithm = 'ball_tree', leaf_size = single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5,scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "\n",
    "    subplot(leaf_size_list, ave_scores, \"Algorithm Ball tree leaf_size\") # using the function to plot x and y values \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    leaf_size_list = list(range(1,30)) # a list of KNN metrics \n",
    "    for single_val in leaf_size_list:  # looping through each value in the list variable\n",
    "        model = KNeighborsClassifier(algorithm = 'kd_tree', leaf_size = single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5,scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "\n",
    "    subplot(leaf_size_list, ave_scores, \"Algorithm Kd leaf_size\") # using the function to plot x and y values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d252b80d",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18d356",
   "metadata": {},
   "source": [
    "## Plotting the KNN's with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c439f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K_NN_plot_Values(X_over,y_over)  # PLots KNN Cross Val score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210b294",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61341a2",
   "metadata": {},
   "source": [
    "# Without any model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a42d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe5856",
   "metadata": {},
   "source": [
    "# Using Cross Validation hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202954de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(weights = 'distance', n_neighbors = 1), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbe7b2",
   "metadata": {},
   "source": [
    "# Random Search plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec1faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Random_search_plot(sorted_list1, sorted_list2, sorted_uniform, sorted_distance, single_val):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function Random_search_plot is used to make a plot for the random search out put for KNN.\n",
    "    \n",
    "    The first parameter sorted_list1 is a list used for the first x axis.\n",
    "    \n",
    "    The secound parameter sorted_list2 is a list used for the secound x axis.\n",
    "    \n",
    "    The third parameter sorted_uniform is a list  used for the first y axis.\n",
    "    \n",
    "    The fourth parameter sorted_distance is a list  used for the second y axis.\n",
    "    \n",
    "    The fifth parameter single_val is used as the title of the plot\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "    plt.title(\"Random Search Hyper parameter Comparison with \" + single_val + \" metric\",\\\n",
    "              fontsize=25, color=\"blue\")  # setting the plot title.\n",
    "    plt.plot(sorted_list1,sorted_uniform , \"--\",marker = \"o\", label=\"weights uniform\", color=\"red\")  # setting the \n",
    "                                                                                                     # uniform variables \n",
    "                                                                # values to the plot on the y axis and K_list  on the x axis.\n",
    "    plt.plot(sorted_list2,sorted_distance , \":\",marker = \"*\", label=\"weights distant\", color=\"blue\")  # setting the distant \n",
    "                                                            # variables values to the plot on the y axis and K_list  \n",
    "                                                           # on the x axis.\n",
    "    plt.xlabel(\"Number of nearest neighbours\", fontsize=20)  # Setting the x label.\n",
    "    plt.ylabel(\"Avarage CV Score\", fontsize=20)  # setting the y label.\n",
    "    plt.legend(loc='upper left')   # setting the legend.\n",
    "    plt.grid()  # setting a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91278327",
   "metadata": {},
   "source": [
    "# sub function to preform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223fde8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rand_search_fun(typeofmodelandprams, dict_prams,crossval, X, y):  # Function takes in the model type, \n",
    "                                                            # number of crossvalidation sand X and y values as hyperparameters.\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    The function rand_search_fun performs random search on a model. It prints the best results and \n",
    "    the hyperparametrs used to obtain those results and then it plots those results.\n",
    "    \n",
    "    The first parameter typeofmodelandprams is the type of model used on which random search is performed on.\n",
    "    \n",
    "    The secound parameter dict_prams is a dictinory of hyperparameters to be used in the random search.\n",
    "    \n",
    "    The third parameter crossval is the number of cross validations to be performed.\n",
    "    \n",
    "    The fourth parameter X is the features.\n",
    "    \n",
    "    The fifth parameter y is the labels.\n",
    "    \n",
    "    \n",
    "    The function rand_search_fun returns the results of the random search.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    model = typeofmodelandprams  # creating an instance of the object.\n",
    "    parameters = [dict_prams]  # hyper parameters for the random search \n",
    "    rand_search = RandomizedSearchCV(\n",
    "                           model,\n",
    "        #estimator = model,  # model\n",
    "                           #param_distributions = parameters,  # hyper paramaters \n",
    "                           parameters,\n",
    "                           scoring = 'f1_macro',  # score measurement\n",
    "                           cv = crossval, # number of cross validations \n",
    "                           n_jobs = -1, # selecting all possible paramaters to go through to get the best model possible \n",
    "                           return_train_score=False, # train score is false as it can be computationaly \n",
    "                                                  # expensive. without storing the traning score the grd search is fater\n",
    "                           n_iter=10,  # setting the number of iterations\n",
    "                           random_state=5)  \n",
    "    rand_search.fit(X, y)  # applying the search on our model.\n",
    "    #print(pd.DataFrame(rand_search.cv_results_)[[\"mean_test_score\",\"params\"]])\n",
    "\n",
    "    best_accuracy = rand_search.best_score_  # the best accuracy \n",
    "    best_parameters = rand_search.best_params_  # the best paramaters that gave the best accurecy\n",
    "    print(\"Best f1 score: {:.2f} %\".format(best_accuracy*100))  # printing best accuracy\n",
    "    print(\"Best Parameters:\", best_parameters)  # printing the best parameters\n",
    "    \n",
    "\n",
    "\n",
    "    return rand_search  # return random search value.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93807905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a10e3e8",
   "metadata": {},
   "source": [
    "# Performs full Random Search on KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520c887",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10de09f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def KNN_full_rand_search(X, y):  # performs randomized search\n",
    "\n",
    "    \"\"\"\n",
    "    The function KNN_full_rand_search performs random search on KNN model. It prints the best results and \n",
    "    the hyperparametrs used to obtain those results and then it plots those results.\n",
    "    \n",
    "    The first parameter X is the features.\n",
    "    \n",
    "    The secound parameter y is the labels.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    metric_list =  ['minkowski','euclidean','manhattan']\n",
    "    k_list = list(range(1,31))  # list from 1 - 30 (will be used as KNN's)\n",
    "    for single_val in metric_list:\n",
    "        weight_list = [\"uniform\"]  # weights list uniform and distance\n",
    "        para_rand = dict(n_neighbors=k_list,weights=weight_list, metric=[single_val])  # adding the above lists in a dictinorr.\n",
    "        rand_search = rand_search_fun(KNeighborsClassifier(), para_rand, 5, X, y)  # Using the grid search gunction with\n",
    "                                                                                                       # arguments given \n",
    "\n",
    "        uniform = []  # creating a empty list\n",
    "        k_list1 = []  # creating a empty list\n",
    "        for i in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                                          # the mean_test_score\n",
    "\n",
    "                uniform.append(rand_search.cv_results_[\"mean_test_score\"][i])  # appending the uniform values ot the \n",
    "                                                                               # uniform variable.\n",
    "                k_list1.append(rand_search.cv_results_[\"param_n_neighbors\"][i])  # appedning the KNN's to the K_list1.\n",
    "\n",
    "        sorted_uniform = []  # creating a empty list\n",
    "        sorted_list1 = k_list1.copy()  # creating a copy of the K_list1 variables values.\n",
    "        sorted_list1.sort()   # sorting the KNNs\n",
    "        for i in range(len(sorted_list1)):  # Looping through the lenght of the sorted_list1 variable.\n",
    "            for j in range(len(k_list1)):  # Looping through the lenght of the K_list1 variable.\n",
    "                if sorted_list1[i] == k_list1[j]:  # checking that if the values of sorted_list1[i] is equal to k_list1[j]\n",
    "                    sorted_uniform.append(uniform[j])  # appeding the unifrom[j] values to the sorted_uniform list.\n",
    "\n",
    "        weight_list = [\"distance\"]  # weights list distance\n",
    "        para_rand = dict(n_neighbors=k_list,weights=weight_list,metric=[single_val])  # adding the above lists in a dictinory.\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rand_search = rand_search_fun(KNeighborsClassifier(), para_rand, 5, X, y)  # Using the grid search gunction with \n",
    "                                                                                  # arguments given \n",
    "\n",
    "        distance = []  # creating a empty list\n",
    "        k_list2 = []  # creating a empty list\n",
    "        for i in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                                          # the mean_test_score\n",
    "                distance.append(rand_search.cv_results_[\"mean_test_score\"][i])  # appending the distance values ot the \n",
    "                                                                               # distance variable.\n",
    "                k_list2.append(rand_search.cv_results_[\"param_n_neighbors\"][i])  # appedning the KNN's to the K_list2.\n",
    "\n",
    "        sorted_distance = []  # creating a empty list\n",
    "        sorted_list2 = k_list2.copy()   # creating a copy of the K_list2 variables values.\n",
    "        sorted_list2.sort()  # sorting the KNNs\n",
    "        for i in range(len(sorted_list2)):  # Looping through the lenght of the sorted_list2 variable.\n",
    "            for j in range(len(k_list2)):  # Looping through the lenght of the K_list2 variable.\n",
    "                if sorted_list2[i] == k_list2[j]:  # checking that if the values of sorted_list2[i] equal  k_list2[j]\n",
    "                    sorted_distance.append(distance[j])  # appeding the unifrom[j] values to the sorted_uniform list.\n",
    "\n",
    "\n",
    "        \n",
    "        Random_search_plot(sorted_list1, sorted_list2, sorted_uniform, sorted_distance, single_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9089ede",
   "metadata": {},
   "source": [
    "## Random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a8d9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_full_rand_search(X_over, y_over)  # performs random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34af8a",
   "metadata": {},
   "source": [
    "# Grid Search plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e71290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def grid_search_plot(distance, uniform, k_list, single_val):\n",
    "    \n",
    "    \n",
    "        \"\"\"\n",
    "        The function grid_search_plot is used to make a plot for the grid search out put for KNN.\n",
    "\n",
    "        The first parameter distance is a list used for the second y axis.\n",
    "\n",
    "        The secound parameter uniform is a list used for the first y axis.\n",
    "\n",
    "        The third parameter k_list is a list used for the first x and second axis.\n",
    "\n",
    "        The fourth parameter single_val is used as the title of the plot\n",
    "\n",
    "\n",
    "        \"\"\" \n",
    "\n",
    "    \n",
    "        plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "        plt.title(\"Grid Search Hyper parameter Comparison with \" + single_val + \" metric\",\\\n",
    "              fontsize=25, color=\"blue\")  # setting the plot title.\n",
    "        plt.plot(k_list,uniform , \"--\", marker = \"o\", label=\"weights uniform\", color=\"red\")  # setting the uniform \n",
    "                                                      # variables values to the plot on the y axis and K_list  on the x axis.\n",
    "        plt.plot(k_list,distance ,\":\", marker = \"*\", label=\"weights distant\", color=\"blue\")  # setting the distant \n",
    "                                                         # variables values to the plot on the y axis and K_list  on the x axis.\n",
    "        plt.xlabel(\"Number of nearest neighbours\",fontsize=20)  # Setting the x label.\n",
    "        plt.ylabel(\"Avarage CV Score\",fontsize=20)  # setting the y label.\n",
    "        plt.legend(loc='lower left')  # setting the legend.\n",
    "        plt.grid()  # setting a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88ca26",
   "metadata": {},
   "source": [
    "# Sub function to preform Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd20d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Grid_search_fun(typeofmodelandprams, dict_prams, crossval, X, y):  # Function takes in the model type,\n",
    "                                                           # number of crossvalidation sand X and y values as hyperparameters.\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    The function Grid_search_fun performs grid search on a model. It prints the best results and \n",
    "    the hyperparametrs used to obtain those results and then it plots those results.\n",
    "    \n",
    "    The first parameter typeofmodelandprams is the type of model used on which random search is performed on.\n",
    "    \n",
    "    The secound parameter dict_prams is a dictinory of hyperparameters to be used in the random search.\n",
    "    \n",
    "    The third parameter crossval is the number of cross validations to be performed.\n",
    "    \n",
    "    The fourth parameter X is the features.\n",
    "    \n",
    "    The fifth parameter y is the labels.\n",
    "    \n",
    "    \n",
    "    The function Grid_search_fun returns the results of the gird search.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    model = typeofmodelandprams  # creating an instance of the object.\n",
    "    parameters = [dict_prams]  # hyper parameters for the grid search\n",
    "    grid_search = GridSearchCV(estimator = model,  # model\n",
    "                           param_grid = parameters,  # hyper paramaters \n",
    "                           scoring = 'f1_macro',  # score measurement\n",
    "                           cv = crossval, # number of cross validations \n",
    "                           n_jobs = -1, return_train_score=False)  # selecting all possible paramaters to go \n",
    "    # through to get the best model possible # train score is false as it can be computationaly expensive. \n",
    "    # without storing the traning score the grd search is fater\n",
    "    grid_search.fit(X, y)  # applying the search on our model.\n",
    "    #print(pd.DataFrame(grid_search.cv_results_)[[\"mean_test_score\",\"params\"]])\n",
    "\n",
    "    best_accuracy = grid_search.best_score_  # the best accuracy \n",
    "    best_parameters = grid_search.best_params_  # the best paramaters that gave the best accurecy\n",
    "    print(\"Best f1 score: {:.2f} %\".format(best_accuracy*100))  # printing best accuracy\n",
    "    print(\"Best Parameters:\", best_parameters)  # printing the best parameters\n",
    "    \n",
    "\n",
    "\n",
    "    return grid_search  # returns grid search value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26aebc",
   "metadata": {},
   "source": [
    "# Performs full grid search for KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09b0f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def KNN_full_grid_search(X, y):  # Performs grid search.\n",
    "\n",
    "        \"\"\"\n",
    "        The function KNN_full_grid_search performs grid search on KNN model. It prints the best results and \n",
    "        the hyperparametrs used to obtain those results and then it plots those results.\n",
    "\n",
    "        The first parameter X is the features.\n",
    "\n",
    "        The secound parameter y is the labels.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        single_val =  ['minkowski'] \n",
    "\n",
    "            \n",
    "        k_list = list(range(1,31))  # list from 1 - 31 (will be used as KNN's)\n",
    "        weight_list = [\"uniform\", \"distance\"]  # weights list uniform and distance\n",
    "        para_grid = dict(n_neighbors=k_list,weights=weight_list,metric=[single_val])  \n",
    "                                                                       # adding the above lists in a dictinary.\n",
    "\n",
    "\n",
    "\n",
    "        grid_search = Grid_search_fun(KNeighborsClassifier(n_neighbors=k_list), para_grid, 5, X, y)  # Using the grid \n",
    "                                                                                 # search function with arguments given \n",
    "\n",
    "        grid_search.cv_results_[\"mean_test_score\"] # looking at mean test score\n",
    "\n",
    "        uniform = []  # a empty list is created\n",
    "        for i in range(len(grid_search.cv_results_[\"mean_test_score\"])):  # getting all even number \n",
    "                                                                               # indexes using a for loop.\n",
    "            if grid_search.cv_results_[\"param_weights\"][i] == \"uniform\":\n",
    "\n",
    "                uniform.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the unifrom values to the\n",
    "                                                                              # varibale unifrom.\n",
    "\n",
    "        distance = []  # a empty list is created\n",
    "        for i in range(len(grid_search.cv_results_[\"mean_test_score\"])):  # getting all odd number indexes \n",
    "                                                                               # using a for loop.\n",
    "            if grid_search.cv_results_[\"param_weights\"][i] == \"distance\":\n",
    "                distance.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the distance values to the \n",
    "                                                                            # varibale distance.\n",
    "\n",
    "        grid_search_plot(distance, uniform, k_list, single_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca219f9",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419518b",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b62ada",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_full_grid_search(X_over, y_over)  # performs grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd42a4",
   "metadata": {},
   "source": [
    "# Model Evaluation using hyperparameters obtained using.\n",
    "# Cross Valadation\n",
    "# Random Search\n",
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0905e",
   "metadata": {},
   "source": [
    "# Function to evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a95fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Classifier_function(model, X_train, y_train,X_test,y_test, title):  # function takes the name of the \n",
    "    \n",
    "    \n",
    "  \"\"\"\n",
    "    The Classifier_function Checks, predicted/actual results , checks testing and traning scores, \n",
    "    Checks Actual values classified correctly and wrongly Checks accuracy, precision, recall,  f1 \n",
    "    scores and area under the curve.\n",
    "    It plots a confusion matix with accuracy, precision, recall,  f1 scores given.\n",
    "    \n",
    "    The first parameter is model the model to evaluate.\n",
    "    \n",
    "    The secound parameter X_train is the variable contaning training datas features.\n",
    "    \n",
    "    The third parameter y_train is the variable contaning training datas label.\n",
    "    \n",
    "    The fourth parameter X_test is the variable contaning testing datas features.\n",
    "    \n",
    "    The fifth parameter y_test is the variable contaning testing datas label.\n",
    "    \n",
    "    The sixth parameter is the string which will be used as the title for the confusion matrix.\n",
    "    \n",
    "    The Classifier_function function returns the train_accuracy,test_accuracy , precision, recall,\n",
    "    f1_score and Area_under_the_curve of a given model. \n",
    "    \n",
    "  \"\"\"\n",
    "                                                               # model used, the x and y traning and testing sets.\n",
    "  model.fit(X_train, y_train)  # Building the k-nearest neighbors classification model.\n",
    "\n",
    "\n",
    "  y_test_p = model.predict(X_test)  # Predicted results.\n",
    "  print(\"  results\\npred-Actual\")  # printing predicted and real values.\n",
    "  print(np.concatenate((y_test_p.reshape(len(y_test_p),1),y_test.reshape(len(y_test),1)),1))  # Predicted results and \n",
    "                                                                                       #  real results in a np array.\n",
    "   \n",
    "\n",
    "  train_accuracy = round(model.score(X_train,y_train),2) * 100  # Getting traing accuracy multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100\n",
    "  test_accuracy = round(model.score(X_test,y_test),2) * 100  # Getting testing accuracy multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100\n",
    "\n",
    "  print(\"Model train accuracy: \", train_accuracy, \"%\")  # printing the model accurcy. \n",
    "  print(\"Model test accuracy: \", test_accuracy, \"%\")  # printing the model accurcy. \n",
    "\n",
    "\n",
    "  print(\"\\n\\n\")  # printing a new line.\n",
    "  # getting Accuracy or recall or precision or specificity\n",
    "  y_test_pred = model.predict(X_test)  # predicted results\n",
    "  \n",
    "  cReport = classification_report(y_test,y_test_pred)  # creating a Classification report\n",
    "  print(cReport)  # creating a Classification report\n",
    "  \n",
    "  cm = confusion_matrix(y_test, y_test_p)  # creating the confusion matrix\n",
    "  cm2 = multilabel_confusion_matrix(y_test, y_test_pred)  # creating a mutable confusion matrix\n",
    "\n",
    "\n",
    "  precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_test_pred)  # getting the precision,\n",
    "                                                                                          # recall and f1score for later use.\n",
    "  accuracy  = round(np.trace(cm) / float(np.sum(cm)), 2) * 100  # getting aaccuracy and multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100.\n",
    "  precision = round(np.mean(precision),2) * 100  # multipling precision variables mean by 100 after rounding it by\n",
    "                                                #  2 to get a score between 0 to 100.\n",
    "  recall = round(np.mean(recall),2) * 100  # multipling recall variables mean by 100 after rounding it by 2 to \n",
    "                                           # get a score between 0 to 100.\n",
    "  f1_score = round(np.mean(f1_score),2) * 100  # multipling f1_score variables mean by 100 after rounding \n",
    "                                               # it by 2 to get a score between 0 to 100.\n",
    "\n",
    "  lable_list = []  # creating a empty list\n",
    "\n",
    "  for i in range(len(cm)):  # looping in the range of the length of the confusion matrix.\n",
    "    for j in range(len(cm)):  # looping in the range of the length of the confusion matrix.\n",
    "        if j == i:  # if the value of j is equal to the value of i.\n",
    "            # the below code appends the Actual Values Classified correctly to the variable lable_list.\n",
    "            lable_list.append(\"Actual \"+ str(i) +\"\\n\" + \"calssified as \"+ str(j) +\"\\n\" + str(cm[i][j]) + \"\\n\"+ \\\n",
    "                              str(round(cm[i][j]/np.sum(cm),2)) + \" %\")\n",
    "\n",
    "        else:   # otherwise\n",
    "            #  the below function appends the actual values classified wrongly to the variable lable list.\n",
    "            lable_list.append(\"Actual \"+ str(i) +\"\\n\" + \"calssified as \"+ str(j) + \"\\n\"  + str(cm[i][j]) + \"\\n\"+ \\\n",
    "                              str(round(cm[i][j]/np.sum(cm),2)) + \" %\")\n",
    "\n",
    "            \n",
    "  lable_list = np.asarray(lable_list).reshape(len(cm),len(cm))  # resahping the label list as a numpy array to be \n",
    "                                                                # used in plotting the confusion matrix\n",
    "  \n",
    "  #  the variable function will be will be used to display the results of the evaluation to the confusion matrix.\n",
    "  total_score = (\"Accuracy:   \" + str(accuracy) +\" %\" + \"\\nPrecison:    \"  + str(precision)  +\" %\" + \"\\nRecall:        \" +\\\n",
    "                 str(recall)  +\" %\" + \"\\nF1 score:    \"  + str(f1_score) +\" %\") \n",
    "\n",
    "\n",
    "  # Below is the code used to plot the confusion matrix.\n",
    "  plt.figure(figsize = (12,9))  # sets the size of the matrix\n",
    "  disp = sns.heatmap(cm, annot=lable_list, fmt='', cmap='Blues')  # displays the results of the actual values \n",
    "                                                                 #  classified wrongly and correctly.                       \n",
    "  disp.plot()  # displaying data in plot\n",
    "  plt.title(title, fontsize=25)  # adding a title to plot\n",
    "  plt.ylabel('True label', fontsize=20)  # adding a y axis to the plot.\n",
    "  plt.xlabel('Predicted label' +\"\\n\\nScores\\n\" +total_score, fontsize=20)  # adding a x axis to the plot\n",
    "  plt.show()  # showing the plot\n",
    "\n",
    "\n",
    "    \n",
    "  y_pred_proba = model.predict_proba(X_test) \n",
    "  Area_under_the_curve = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\")\n",
    "  print(\"Area under the curve: \", Area_under_the_curve)   \n",
    "  result_list = train_accuracy,test_accuracy , precision, recall, f1_score,Area_under_the_curve  # returning the results\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "  return result_list  # returns the results from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucidedataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274dac67",
   "metadata": {},
   "source": [
    "# Feature Scaling and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6542b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def featurescaling(Scaler, X_train, X_test, y_train, y_test, Modelandprams ,Modelname):\n",
    "    \n",
    "    \"\"\"\n",
    "    The featurescaling fundtion feature scales given features and then Checks, predicted/actual results , checks testing \n",
    "    and traning scores, Checks Actual values classified correctly and wrongly Checks accuracy, precision, recall,  f1 \n",
    "    scores and area under the curve.\n",
    "    It plots a confusion matix with accuracy, precision, recall,  f1 scores given.\n",
    "    \n",
    "    The first parameter is typpe of scaling technique to use.\n",
    "    \n",
    "    The secound parameter X_train is the variable contaning training datas features.\n",
    "    \n",
    "    The third parameter y_train is the variable contaning training datas label.\n",
    "    \n",
    "    The fourth parameter X_test is the variable contaning testing datas features.\n",
    "    \n",
    "    The fifth parameter y_test is the variable contaning testing datas label.\n",
    "    \n",
    "    The sixth parameter is parameter is model the model to evaluate.\n",
    "    \n",
    "    The seventh parameter is the string which will be used as the title for the confusion matrix.\n",
    "    \n",
    "    The featurescaling function returns the train_accuracy,test_accuracy , precision, recall,\n",
    "    f1_score and Area_under_the_curve of a given model after feature scaling. \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sc = Scaler # creating an instance of the object.\n",
    "    \n",
    "\n",
    "    X_train[:, 55:] = sc.fit_transform(X_train[:, 55:])  # Scaling x_train\n",
    "    X_test[:,55:] = sc.transform(X_test[:, 55:])  # Scaling y_train\n",
    "    \n",
    "\n",
    "    train_accuracy,test_accuracy , precision, recall, f1_score, Area_under_the_curve = Classifier_function(Modelandprams ,\\\n",
    "                X_train, y_train,X_test, y_test, Modelname)  \n",
    "    # Performs traing, testing prediction.\n",
    "    # performs precision, recall, f1-score and support prediction\n",
    "    # plots a confusion matrix\n",
    "    # returns the traing, testing, precision, recall, f1-score\n",
    "    return train_accuracy,test_accuracy , precision, recall, f1_score, Area_under_the_curve \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce2159",
   "metadata": {},
   "source": [
    "# Choosing the best neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da6614",
   "metadata": {},
   "source": [
    "# With 15 neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5540f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors = 15, weights ='distance'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da6614",
   "metadata": {},
   "source": [
    "# With 3 neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a93b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors = 3, weights ='distance'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bf55a",
   "metadata": {},
   "source": [
    "# With 1 neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723826e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors = 1, weights ='distance'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aca461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be6cfe",
   "metadata": {},
   "source": [
    "## Checking predicted/actual results\n",
    "## Checking testing and traning scores\n",
    "## Checking Actual values classified correctly and wrongly.\n",
    "## Checking accuracy, precision, recall and f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68632cd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(KNeighborsClassifier(n_neighbors = 15, weights ='distance'), X_train_over,\\\n",
    "                    y_train_over, X_test_over, y_test_over, \"KNN Model\")  \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577b595",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5988127",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763e0d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for neighbour in [1, 3, 15]:  # looping from a list.\n",
    "    print(\"When neighbour = \", neighbour)  # printing output\n",
    "    featurescaling(StandardScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               KNeighborsClassifier(n_neighbors = neighbour, weights ='distance') ,\"KNN Model\")\n",
    "\n",
    "# performs standard scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da765b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               KNeighborsClassifier(n_neighbors = 15, weights ='distance') ,\"KNN Model\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37401f12",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29422ff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(RobustScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               KNeighborsClassifier(n_neighbors = 15, weights ='distance') ,\"KNN Model\")\n",
    "# performs robust scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5f6e5",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf773741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(Normalizer(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               KNeighborsClassifier(n_neighbors = 15, weights ='distance') ,\"KNN Model\")\n",
    "# Performs normalization scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce621cb",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e593ff2",
   "metadata": {},
   "source": [
    "# Original results without hyperparameter Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5e53a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(KNeighborsClassifier(), X_train_over, y_train_over,X_test_over, y_test_over, \"KNN Model\")  \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789143d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7acb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5f1eb79",
   "metadata": {},
   "source": [
    "# Best Score and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da765b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71995aaf",
   "metadata": {},
   "source": [
    "# results with hyparameters improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "           KNeighborsClassifier(n_neighbors = 3, weights ='distance') ,\"KNN Model\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e565c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "           KNeighborsClassifier(n_neighbors = 15, weights ='distance') ,\"KNN Model\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd4af5",
   "metadata": {},
   "source": [
    "# Improved model full Evaluation with feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da6614",
   "metadata": {},
   "source": [
    "# With 15 neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5540f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors = 15, weights ='distance'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da6614",
   "metadata": {},
   "source": [
    "# With 3 neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a93b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors = 3, weights ='distance'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bf55a",
   "metadata": {},
   "source": [
    "# With 1 neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723826e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(KNeighborsClassifier(n_neighbors = 1, weights ='distance'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b45146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd106a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3d6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5295efae",
   "metadata": {},
   "source": [
    "# Random forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb617071",
   "metadata": {},
   "source": [
    "## k-fold cross-validation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb60f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def subplot(list_for_plot, ave_scores, hyper_pram_to_use_name):   # A function with parameters given.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    The function subplot plots a linear plot and shows the best results using two lists \n",
    "    the fist one acting as a label to the second list and the second list being scores.\n",
    "    \n",
    "    The first parameter list_for_plot is the X label.\n",
    "    \n",
    "    The second parameter ave_scores is the y label.\n",
    "    \n",
    "    The thrid paramater hyper_pram_to_use_name is the the titile for the plot.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    plt.figure()  # plot a figure\n",
    "    plt.title(\"Best \" + hyper_pram_to_use_name + \" Selection\",fontsize=18)  # Displays plot title\n",
    "    plt.plot(list_for_plot, ave_scores)  # Displays description of the plots x and y labels.\n",
    "    plt.xlabel(hyper_pram_to_use_name +\" values\")  # Displays the x axis for the plot\n",
    "    plt.ylabel(\"Average CV model f1 score\")  # Displays the y axis for the plot\n",
    "    plt.legend([hyper_pram_to_use_name], loc=\"lower right\")  # adds a legend to the plot.\n",
    "    plt.grid()  # adds a gird to the plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6f50f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RandomForest_plot_Values(X,y, n_estimators_list, max_depth_list, min_samples_leaf_list, min_samples_split_list): \n",
    "                                                                                  # Values required for plotting\n",
    "    \n",
    "    \"\"\"\n",
    "    The RandomForest_plot_Values performs cross valadation on the Random Forest models provided hyperparametes, prints \n",
    "    the best hyperparameters that give the best reults and plots the results.\n",
    "    \n",
    "    The first parameter X takes the features.\n",
    "    \n",
    "    The first parameter y takes the lables.\n",
    "    \n",
    "    The third parameter n_estimators_list is  a list of n_estimators.\n",
    "    \n",
    "    The fourth parameter max_depth_list is  a list of max_depth.\n",
    "    \n",
    "    The fifth parameter min_samples_leaf_list is  a list of min_samples_leaf.\n",
    "    \n",
    "    The sixth parameter min_samples_split_list is  a list of min_samples_split.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in n_estimators_list:  # looping through each value in the list\n",
    "        model = RandomForestClassifier(n_estimators=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(n_estimators_list, ave_scores, \"n_estimators\") # using the function to plot x and y values.\n",
    "    \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in max_depth_list:  # looping through each value in the list\n",
    "        model = RandomForestClassifier(max_depth=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(max_depth_list, ave_scores, \"max_depth\") # using the function to plot x and y values.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in min_samples_leaf_list:  # looping through each value in the list\n",
    "        model = RandomForestClassifier(min_samples_leaf=single_val, scoring = 'f1_macro')   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5)  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(min_samples_leaf_list, ave_scores, \"min_samples_leaf\") # using the function to plot x and y values.\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in min_samples_split_list:  # looping through each value in the list\n",
    "        model = RandomForestClassifier(min_samples_split=single_val, scoring = 'f1_macro')   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5)  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    subplot(min_samples_split_list, ave_scores, \"min_samples_split\") # using the function to plot x and y values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d43b7",
   "metadata": {},
   "source": [
    "## Plotting the Random Forest with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5581d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_estimators_list  = [10,50,100,200, 300, 500]  # Setting the values for the list.\n",
    "max_depth_list  = [None, 4,5,6,7,8 ,80, 90, 100, 200,500]  # Setting the values for the list.\n",
    "min_samples_leaf_list = list(range(1,30))  # Setting the values for the list.\n",
    "min_samples_split_list = list(range(2,30)) # Setting the values for the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3c07a",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627c91f",
   "metadata": {},
   "source": [
    "## Plotting the Random forest with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a77699",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RandomForest_plot_Values(X_over,y_over, n_estimators_list, max_depth_list, min_samples_leaf_list, min_samples_split_list) \n",
    "                                                                                 # PLots  Cross Val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68405be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def n_estimation(X,y):  # a function with parameters given\n",
    "    \n",
    "    \"\"\"\n",
    "    The n_estimation performs cross valadation on the Random Forest models n_estimators parameter prints \n",
    "    the best hyperparameters that give the best reults and plots the results\n",
    "    \n",
    "    The first parameter X takes the features.\n",
    "    \n",
    "    The first parameter y takes the lables. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators_list = [10,15,25,30,45,50,60,75,90,95,100,105,110,125,130,145,150,160,175,190,200,210,\\\n",
    "                         225,230,250,275,300]  # a list of n_estimators.\n",
    "    ave_scores = []  # Creating a empty list  \n",
    "    for single_val in n_estimators_list:  # looping through each value in the list\n",
    "        model = RandomForestClassifier(n_estimators=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "\n",
    "    subplot(n_estimators_list, ave_scores, \"n_estimators\") # using the function to plot x and y values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067115fc",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e9f2c",
   "metadata": {},
   "source": [
    "# N estimation improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc4910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_estimation(X_over,y_over)   # PLots Cross Val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147b65f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def max_depth_estimation(X,y):\n",
    "    \n",
    "    \"\"\"\n",
    "    The max_depth_estimation( performs cross valadation on the Random Forest models max_depth parameter prints \n",
    "    the best hyperparameters that give the best reults and plots the results\n",
    "    \n",
    "    The first parameter X takes the features.\n",
    "    \n",
    "    The first parameter y takes the lables. \n",
    "    \n",
    "    \"\"\"\n",
    "    max_depth_list = [None, 1, 5,10, 15,20 ,25, 30,40,45,50, 60,70,75, 80, 85,90,95,100]  # a list of max_depth values.\n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in max_depth_list:  # looping through each value in the list\n",
    "        model = RandomForestClassifier(max_depth=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "\n",
    "    subplot(max_depth_list, ave_scores, \"max_depth\") # using the function to plot x and y values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6fa3e",
   "metadata": {},
   "source": [
    "# Max depth improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1650b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depth_estimation(X_over,y_over) # PLots Cross Val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf025f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_estimators = [10, 75, 150, 225]\n",
    "# max_depth = [10, 50 ,100, 75 , 90]\n",
    "# min_samples_leaf = [1,9, 10]\n",
    "# min_samples_split = [2,16, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf4ddc",
   "metadata": {},
   "source": [
    "# Without any model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983e8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(RandomForestClassifier(), X_over, y_over, 10) \n",
    "                                      # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd38e15",
   "metadata": {},
   "source": [
    "# Using Cross Validation hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f1769",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_list = [90, 95, 100]  # a list of n_estimators\n",
    "md_list = [None, 50, 75]  # a list of max_depth \n",
    "for n in n_list:   # looping through a list\n",
    "    for md in md_list:   # looping through a list\n",
    "        print(\"Result when n_estimators = \", n)  # printing output\n",
    "        print(\"Result when max depth = \", md)  # printing output\n",
    "        crossvalscore(RandomForestClassifier(n_estimators = n, max_depth = md, min_samples_leaf = 1, min_samples_split =2\\\n",
    "                                            ), X_over, y_over, 10)  # Performs cross validation.\n",
    "        print(\"\\n\")  # printing new line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5d7bc",
   "metadata": {},
   "source": [
    "# Full random search on random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df129c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def randomsearchrandomforest(X,y,n_estimators_list,max_depth_list,min_samples_leaf_list,min_samples_split_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function randomsearchrandomforest performs random search on a model. It prints the best results and \n",
    "    the hyperparametrs used to obtain those results and then it plots those results.\n",
    "    \n",
    "    \n",
    "    The first parameter X is the feature.\n",
    "    \n",
    "    The secound parameter y is the labels\n",
    "    \n",
    "    The third parameter n_estimators_list is the n_estimators.\n",
    "    \n",
    "    The fourth parameter max_depth_list is the max_depth.\n",
    "    \n",
    "    The fifth parameter min_samples_leaf_list is the min_samples_leaf.\n",
    "    \n",
    "    The sixth parameter min_samples_split_list is the min_samples_split.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    bootstrap_list = [True, False]   # a lsit with values specified.\n",
    "    max_features_list  = ['auto', 'sqrt', 'log2']  # Setting the values for the list.\n",
    "    criterion_list  = ['gini', 'entropy']  # Setting the values for the list.\n",
    "    for i in range(len(criterion_list)):\n",
    "        for j in range(len(max_features_list)):\n",
    "            list1 = []  # creating a empty list\n",
    "            list2 = []  # creating a empty list\n",
    "            para_rand = dict(n_estimators = n_estimators_list, max_depth = max_depth_list, min_samples_leaf = \\\n",
    "                             min_samples_leaf_list,min_samples_split = min_samples_split_list,\\\n",
    "                             max_features = [max_features_list[j]],  criterion = [criterion_list[i]],\\\n",
    "                             bootstrap = bootstrap_list)  # adding the above \n",
    "                                                                                         # lists in a dictinary.\n",
    "            rand_search = rand_search_fun(RandomForestClassifier(), para_rand, 5, X, y)  # Using the grid search gunction with      \n",
    "\n",
    "            ## Random search # Using the grid search gunction with   \n",
    "            for m in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                      # the mean_test_score\n",
    "\n",
    "                    list1.append(rand_search.cv_results_[\"mean_test_score\"][m])  # appending the values to list \n",
    "\n",
    "                    list2.append(rand_search.cv_results_[\"param_bootstrap\"][m])  # appedning the values to the list2.\n",
    "\n",
    "                    sorted_list1= []\n",
    "                    sorted_list2 = list2.copy()  # creating a copy of the list2 variables values.\n",
    "                    sorted_list2.sort()   # sorting the list2\n",
    "                    for k in range(len(sorted_list2)):  # Looping through the lenght of the sorted_list2 variable.\n",
    "                        for l in range(len(list2)):  # Looping through the lenght of the list2 variable.\n",
    "                            if sorted_list2[k] == list2[l]:  # checking that if the values of sorted_list2[i] \n",
    "                                # is equal to list2[j]\n",
    "                                sorted_list1.append(list1[l])  # appeding the list1[j] values to the sorted_list1 list.\n",
    "\n",
    "\n",
    "            plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "            plt.title(\"Random Search Hyper parameter Comparison with \"+ criterion_list[i] +\" criterion\", \\\n",
    "                      fontsize=25, color=\"blue\")  # setting the plot title.\n",
    "            plt.plot(sorted_list2,sorted_list1 , \"--\", marker = \"o\", label=\"max features \" +  max_features_list[j],\\\n",
    "                     color=\"red\")  # setting the best\n",
    "                                            # variables values to the plot on the y axis and max depth on the x axis.\n",
    "            plt.xlabel('bootstrap',fontsize=20)  # Setting the x label.\n",
    "            plt.ylabel(\"Avarage CV Score\",fontsize=20)  # setting the y label.\n",
    "            plt.legend(loc='upper left')  # setting the legend.\n",
    "            plt.grid()  # setting a grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a691fa",
   "metadata": {},
   "source": [
    "## Random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4ddd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators_list = [100]   # a lsit with values specified.\n",
    "max_depth_list = [50]   # a lsit with values specified.\n",
    "min_samples_leaf_list = [1]   # a lsit with values specified.\n",
    "min_samples_split_list = [2]   # a lsit with values specified.\n",
    "randomsearchrandomforest(X_over,y_over,n_estimators_list,max_depth_list,min_samples_leaf_list,min_samples_split_list)  \n",
    "# function with arguments given        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3926b90",
   "metadata": {},
   "source": [
    "# Full Grid search on random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd71175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def randomforestgridsearch(X, y, n_estimators_list, max_depth_list, min_samples_leaf_list, min_samples_split_list):  # function \n",
    "                                                                                           # with parameters given\n",
    "        \n",
    "    \"\"\"\n",
    "    The function randomforestgridsearch performs grid search on a model. It prints the best results and \n",
    "    the hyperparametrs used to obtain those results and then it plots those results.\n",
    "    \n",
    "    The first parameter X is the feature.\n",
    "    \n",
    "    The secound parameter y is the labels\n",
    "    \n",
    "    The third parameter n_estimators_list is the n_estimators.\n",
    "    \n",
    "    The fourth parameter max_depth_list is the max_depth.\n",
    "    \n",
    "    The fifth parameter min_samples_leaf_list is the min_samples_leaf.\n",
    "    \n",
    "    The sixth parameter min_samples_split_list is the min_samples_split.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    bootstrap_list = [True, False]   # a lsit with values specified.\n",
    "    max_features_list  = ['auto', 'sqrt', 'log2']  # Setting the values for the list.\n",
    "    criterion_list  = ['gini', 'entropy']  # Setting the values for the list.\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(criterion_list)):\n",
    "        if i == 0:\n",
    "            para_grid = dict(n_estimators = n_estimators_list, max_depth = max_depth_list, min_samples_leaf = \\\n",
    "                             min_samples_leaf_list,\\\n",
    "                             min_samples_split = min_samples_split_list,max_features = max_features_list,  \\\n",
    "                             criterion = [criterion_list[i]], bootstrap = bootstrap_list)  # adding the above \n",
    "                                                                                        # lists in a dictinary.\n",
    "            grid_search = Grid_search_fun(RandomForestClassifier(), para_grid, 5, X, y)  # Using the grid search function with     \n",
    "        if i == 1:\n",
    "            para_grid = dict(n_estimators = n_estimators_list, max_depth = max_depth_list, min_samples_leaf = \\\n",
    "                             min_samples_leaf_list,min_samples_split = min_samples_split_list,\\\n",
    "                             max_features = max_features_list,criterion = [criterion_list[i]],\\\n",
    "                             bootstrap = bootstrap_list)  # adding the above \n",
    "                                                                                    # lists in a dictinary.\n",
    "            grid_search2 = Grid_search_fun(RandomForestClassifier(), para_grid, 5, X, y)  # Using the grid search function with \n",
    "                                                                                          # arguments given\n",
    "\n",
    "\n",
    "\n",
    "    list1 = []  # a empty list is created\n",
    "    for i in range(len(grid_search.cv_results_[\"mean_test_score\"])):  # getting all even number \n",
    "                                                                           # indexes using a for loop.\n",
    "        if grid_search.cv_results_[\"param_max_features\"][i] == 'auto':\n",
    "\n",
    "            list1.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the 32 values to the\n",
    "                                                                          # varibale list1.\n",
    "\n",
    "    list2 = []  # a empty list is created\n",
    "    for i in range(len(grid_search.cv_results_[\"mean_test_score\"])):  # getting all odd number indexes \n",
    "                                                                           # using a for loop.\n",
    "        if grid_search.cv_results_[\"param_max_features\"][i] == 'sqrt':\n",
    "            list2.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the 33 values to the \n",
    "                                                                        # varibale list2.\n",
    "\n",
    "    list3 = []  # a empty list is created\n",
    "    for i in range(len(grid_search.cv_results_[\"mean_test_score\"])):  # getting all odd number indexes \n",
    "                                                                           # using a for loop.\n",
    "        if grid_search.cv_results_[\"param_max_features\"][i] == 'log2':\n",
    "            list3.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the 34 values to the \n",
    "                                                                        # varibale lst3.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "    plt.title(\"Grid Search Hyper parameter Comparison with gini criterion\", fontsize=25, color=\"blue\")  \n",
    "                                                                                               # setting the plot title.\n",
    "    plt.plot(bootstrap_list,list1 , \"--\", marker = \"o\", label=\"max features list auto\", color=\"red\")  # setting the best\n",
    "    plt.plot(bootstrap_list,list2 ,\":\", marker = \"*\", label=\"max features list sqrt\", color=\"blue\")  # setting the random \n",
    "    plt.plot(bootstrap_list,list3 ,\":\", marker = \"d\", label=\"max features list log2\", color=\"orange\")  # setting the random \n",
    "                                                    # variables values to the plot on the y axis and max depth on the x axis.\n",
    "    plt.xlabel('bootstrap',fontsize=20)  # Setting the x label.\n",
    "    plt.ylabel(\"Avarage CV Score\",fontsize=20)  # setting the y label.\n",
    "    plt.legend(loc='upper left')  # setting the legend.\n",
    "    plt.grid()  # setting a grid\n",
    "\n",
    "\n",
    "\n",
    "    list1 = []  # a empty list is created\n",
    "    for i in range(len(grid_search2.cv_results_[\"mean_test_score\"])):  # getting all even number \n",
    "                                                                           # indexes using a for loop.\n",
    "        if grid_search2.cv_results_[\"param_max_features\"][i] == 'auto':\n",
    "\n",
    "            list1.append(grid_search2.cv_results_[\"mean_test_score\"][i])  # appending the 32 values to the\n",
    "                                                                          # varibale list1.\n",
    "\n",
    "    list2 = []  # a empty list is created\n",
    "    for i in range(len(grid_search2.cv_results_[\"mean_test_score\"])):  # getting all odd number indexes \n",
    "                                                                           # using a for loop.\n",
    "        if grid_search2.cv_results_[\"param_max_features\"][i] == 'sqrt':\n",
    "            list2.append(grid_search2.cv_results_[\"mean_test_score\"][i])  # appending the 33 values to the \n",
    "                                                                        # varibale list2.\n",
    "\n",
    "    list3 = []  # a empty list is created\n",
    "    for i in range(len(grid_search2.cv_results_[\"mean_test_score\"])):  # getting all odd number indexes \n",
    "                                                                           # using a for loop.\n",
    "        if grid_search2.cv_results_[\"param_max_features\"][i] == 'log2':\n",
    "            list3.append(grid_search2.cv_results_[\"mean_test_score\"][i])  # appending the 34 values to the \n",
    "                                                                        # varibale list3.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "    plt.title(\"Grid Search Hyper parameter Comparison with 31 min samples split\", fontsize=25, color=\"blue\")  \n",
    "                                                                                         # setting the plot title.\n",
    "    plt.plot(bootstrap_list,list1 , \"--\", marker = \"o\", label=\"max features list auto\", color=\"red\")  # setting the best\n",
    "    plt.plot(bootstrap_list,list2 ,\":\", marker = \"*\", label=\"max features list sqrt\", color=\"blue\")  # setting the random \n",
    "    plt.plot(bootstrap_list,list3 ,\":\", marker = \"d\", label=\"max features list log2\", color=\"orange\")  # setting the random \n",
    "                                                    # variables values to the plot on the y axis and max depth on the x axis.\n",
    "    plt.xlabel('bootstrap',fontsize=20)  # Setting the x label.\n",
    "    plt.ylabel(\"Avarage CV Score\",fontsize=20)  # setting the y label.\n",
    "    plt.legend(loc='upper left')  # setting the legend.\n",
    "    plt.grid()  # setting a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419518b",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298381f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators_list = [90]   # a lsit with values specified.\n",
    "max_depth_list = [50]   # a lsit with values specified.\n",
    "min_samples_leaf_list = [1]   # a lsit with values specified.\n",
    "min_samples_split_list = [2]   # a lsit with values specified.\n",
    "randomforestgridsearch(X_over, y_over, n_estimators_list, max_depth_list, min_samples_leaf_list, min_samples_split_list) \n",
    "                                      # function with arguments given.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f8714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d54e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be6cfe",
   "metadata": {},
   "source": [
    "## Checking predicted/actual results\n",
    "## Checking testing and traning scores\n",
    "## Checking Actual values classified correctly and wrongly.\n",
    "## Checking accuracy, precision, recall and f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68632cd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(RandomForestClassifier(n_estimators =90,min_samples_split = 2,\\\n",
    "                            min_samples_leaf = 1, max_depth = 50, bootstrap = False, \\\n",
    "                            max_features = 'sqrt', criterion = 'entropy'), X_train_over, y_train_over,X_test_over, \\\n",
    "                            y_test_over, \"Random Forest\")\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577b595",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5988127",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763e0d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(StandardScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               RandomForestClassifier(n_estimators =90,min_samples_split = 2, min_samples_leaf = 1, max_depth = 50,\\\n",
    "               bootstrap = False, max_features = 'sqrt', criterion = 'entropy') ,\"Random Forest\")\n",
    "\n",
    "# performs standard scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da765b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               RandomForestClassifier(n_estimators =90,min_samples_split = 2, min_samples_leaf = 1, max_depth = 50,\\\n",
    "               bootstrap = False, max_features = 'sqrt', criterion = 'entropy') ,\"Random Forest\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37401f12",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29422ff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(RobustScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               RandomForestClassifier(n_estimators =90,min_samples_split = 2, min_samples_leaf = 1, max_depth = 50,\\\n",
    "               bootstrap = False, max_features = 'sqrt', criterion = 'entropy') ,\"Random Forest\")\n",
    "# performs robust scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5f6e5",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf773741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(Normalizer(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               RandomForestClassifier(n_estimators =90,min_samples_split = 2, min_samples_leaf = 1, max_depth = 50,\\\n",
    "               bootstrap = False, max_features = 'sqrt', criterion = 'entropy') ,\"Random Forest\")\n",
    "# Performs normalization scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f26b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa54f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ce621cb",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741266f",
   "metadata": {},
   "source": [
    "# Original results without hyperparameter Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44342221",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(RandomForestClassifier(), X_train_over, y_train_over,X_test_over, y_test_over, \"Random Forest\")  \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1eb79",
   "metadata": {},
   "source": [
    "# Best Score and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da765b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d818cf2",
   "metadata": {},
   "source": [
    "# Results with hyparameters improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train_over, X_test_over, y_train_over, y_test_over,\\\n",
    "               RandomForestClassifier(n_estimators =90,min_samples_split = 2, min_samples_leaf = 1, max_depth = 50,\\\n",
    "               bootstrap = False, max_features = 'sqrt', criterion = 'entropy') ,\"Random Forest\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf7ac93",
   "metadata": {},
   "source": [
    "# Un_edited full model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6567ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(RandomForestClassifier(), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2a22c",
   "metadata": {},
   "source": [
    "# Improved model full Evaluation with feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3fb6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(RandomForestClassifier(n_estimators =90,min_samples_split = 2, min_samples_leaf = 1,\\\n",
    "                    max_depth = 50,bootstrap = False, max_features = 'sqrt', criterion = 'entropy'), X_over, y_over, 10) \n",
    "# Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b9e3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731f744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5295efae",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6f50f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DecisionTree_plot_Values(X,y, max_depth_list, min_samples_leaf_list, min_samples_split_list, min_weight_fraction_leaf_list,\\\n",
    "                             max_leaf_nodes_list, criterion_list,max_features_list, splitter_list): \n",
    "                                                                                  # Values required for plotting\n",
    "    \"\"\"\n",
    "    The DecisionTree_plot_Values performs cross valadation on the Decision Tree models provided hyperparametes, prints \n",
    "    the best hyperparameters that give the best reults and plots the results.\n",
    "    \n",
    "    The first parameter X takes the features.\n",
    "    \n",
    "    The first parameter y takes the lables.\n",
    "    \n",
    "    The third parameter max_depth_list is  a list of max_depth.\n",
    "    \n",
    "    The fourth parameter min_samples_leaf_list is  a list of min_samples_leaf.\n",
    "    \n",
    "    The fifth parameter min_weight_fraction_leaf_list is  a min_weight_fraction_leaf.\n",
    "    \n",
    "    The sixth parameter max_leaf_nodes_list is  a list of max_leaf_nodes.\n",
    "    \n",
    "    The seventh parameter criterion_list is  a list of criterion.\n",
    "    \n",
    "    The eigth parameter max_features_list is  a max_features.\n",
    "    \n",
    "    The ningth parameter splitter_list is  a list of splitter.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in max_depth_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(max_depth=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(max_depth_list, ave_scores, \"max_depth\") # using the function to plot x and y values.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in min_samples_leaf_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(min_samples_leaf_list, ave_scores, \"min_samples_leaf\") # using the function to plot x and y values.\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in min_samples_split_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(min_samples_split=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    subplot(min_samples_split_list, ave_scores, \"min_samples_split\") # using the function to plot x and y values. \n",
    "    \n",
    "    \n",
    "\n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in min_weight_fraction_leaf_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(min_weight_fraction_leaf=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(min_weight_fraction_leaf_list, ave_scores, \"min_weight_fraction_leaf\") # using the function to plot x and y values.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in max_leaf_nodes_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(max_leaf_nodes=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(max_leaf_nodes_list, ave_scores, \"max_leaf_nodes\") # using the function to plot x and y values.\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in criterion_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(criterion=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(criterion_list, ave_scores, \"criterion\") # using the function to plot x and y values.\n",
    "    \n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in max_features_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(max_features=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    max_features_list[3] = \"None\"\n",
    "    subplot(max_features_list, ave_scores, \"max_features\") # using the function to plot x and y values.\n",
    "    \n",
    "    \n",
    "    ave_scores = []  # Creating a empty list\n",
    "    for single_val in splitter_list:  # looping through each value in the list\n",
    "        model = DecisionTreeClassifier(splitter=single_val)   # creating an instance of a class.\n",
    "        scores = cross_val_score(model,X,y,cv=5, scoring = 'f1_macro')  # Getting the results of the model.\n",
    "        ave_scores.append(round(scores.mean(),3))  # getting the average score from the model and appending \n",
    "                                                  # it to the ave_scores list.\n",
    "    \n",
    "    subplot(splitter_list, ave_scores, \"splitter\") # using the function to plot x and y values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d43b7",
   "metadata": {},
   "source": [
    "## Plotting the Decision tree with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5581d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = [None,1,2,3,4,5,6,7,8,9,10,25,50,75,80,90,100,125,150,175,200,225,250,275,300,500] # a lsit with values \n",
    "                                                                                                        # specified.\n",
    "min_samples_leaf_list = list(range(1,50))  # a lsit with values specified.\n",
    "min_samples_split_list = list(range(2,50))  # a lsit with values specified.\n",
    "min_weight_fraction_leaf_list = [0.0, 0.1,0.2,0.3,0.4,0.5,0.6]  # a lsit with values specified.\n",
    "max_leaf_nodes_list = [None,10,20,30,40,50,60,70,80,90,100,125, 150,175, 200,225,250,275,300]  # a lsit with values specified.\n",
    "min_impurity_decrease = [0.0]  # a lsit with values specified.\n",
    "\n",
    "criterion_list = [\"gini\", \"entropy\"]  # a lsit with values specified.\n",
    "max_features_list = [\"auto\",\"log2\",\"sqrt\", None]  # a lsit with values specified.\n",
    "splitter_list = [\"best\",\"random\"]  # a lsit with values specified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56934203",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627c91f",
   "metadata": {},
   "source": [
    "## Plotting the decision tree with a average Cross-val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a77699",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DecisionTree_plot_Values(X_over,y_over, max_depth_list, min_samples_leaf_list, min_samples_split_list, \\\n",
    "    min_weight_fraction_leaf_list, max_leaf_nodes_list, criterion_list,max_features_list, splitter_list)  # PLots Cross\n",
    "                                                                                                          # Val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac3603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ff24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5eb7f10",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780d463",
   "metadata": {},
   "source": [
    "# Without any model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98475231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(DecisionTreeClassifier(), X_over, y_over, 10) \n",
    "                                      # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd38e15",
   "metadata": {},
   "source": [
    "# Using Cross Validation hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7a412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_leaf_nodes = None, \\\n",
    "                                    min_weight_fraction_leaf = 0.0,  max_depth = 125, criterion = 'entropy', \\\n",
    "                                    max_features = None, splitter = \"random\"), X_over, y_over, 10) \n",
    " # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423886c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850334d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a691fa",
   "metadata": {},
   "source": [
    "## Random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4ddd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = list(range(101,150))   # a lsit with values specified.\n",
    "splitter_list = ['best']   # a lsit with values specified.\n",
    "para_rand = dict(max_depth = max_depth_list, splitter = splitter_list)  # adding the above \n",
    "                                                                                                       # lists in a dictinary.\n",
    "rand_search = rand_search_fun(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_leaf_nodes = None, \\\n",
    "                                    min_weight_fraction_leaf = 0.0,criterion = 'entropy', \\\n",
    "                                    max_features = None), para_rand, 5, X_over, y_over)  \n",
    "                                    # Using the random search function with \n",
    "best = []  # creating a empty list\n",
    "list1 = []  # creating a empty list\n",
    "for i in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                                  # the mean_test_score\n",
    "\n",
    "        best.append(rand_search.cv_results_[\"mean_test_score\"][i])  # appending the best values ot the \n",
    "                                                                       # best variable.\n",
    "        list1.append(rand_search.cv_results_[\"param_max_depth\"][i])  # appedning the values to the list1.\n",
    "\n",
    "sorted_best= []  # creating a empty list\n",
    "sorted_list1 = list1.copy()  # creating a copy of the list1 variables values.\n",
    "sorted_list1.sort()   # sorting the KNNs\n",
    "for i in range(len(sorted_list1)):  # Looping through the lenght of the sorted_list1 variable.\n",
    "    for j in range(len(list1)):  # Looping through the lenght of the list1 variable.\n",
    "        if sorted_list1[i] == list1[j]:  # checking that if the values of sorted_list1[i] is equal to list1[j]\n",
    "            sorted_best.append(best[j])  # appeding the best[j] values to the sorted_best list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a83408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = list(range(101,150))   # a lsit with values specified.\n",
    "splitter_list = ['random']   # a lsit with values specified.\n",
    "para_rand = dict(max_depth = max_depth_list, splitter = splitter_list)  # adding the above \n",
    "                                                                                                       # lists in a dictinary.\n",
    "rand_search = rand_search_fun(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_leaf_nodes = None, \\\n",
    "                                    min_weight_fraction_leaf = 0.0,criterion = 'entropy', \\\n",
    "                                    max_features = None), para_rand, 5, X_over, y_over)  \n",
    "                                    # Using the random search function with \n",
    "\n",
    "\n",
    "\n",
    "random = []  # creating a empty list\n",
    "list2 = []  # creating a empty list\n",
    "for i in range(len(rand_search.cv_results_[\"mean_test_score\"])):  # looping through the times the length of \n",
    "                                                                  # the mean_test_score\n",
    "        random.append(rand_search.cv_results_[\"mean_test_score\"][i])  # appending the random values ot the \n",
    "                                                                       # random variable.\n",
    "        list2.append(rand_search.cv_results_[\"param_max_depth\"][i])  # appedning the items to the list2.\n",
    "\n",
    "sorted_random = []  # creating a empty list\n",
    "sorted_list2 = list2.copy()   # creating a copy of the list2 variables values.\n",
    "sorted_list2.sort()  # sorting the list\n",
    "for i in range(len(sorted_list2)):  # Looping through the lenght of the sorted_list2 variable.\n",
    "    for j in range(len(list2)):  # Looping through the lenght of the list2 variable.\n",
    "        if sorted_list2[i] == list2[j]:  # checking that if the values of sorted_list2[i] equal  list2[j]\n",
    "            sorted_random.append(random[j])  # appeding the random[j] values to the sorted_random list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75839d86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "plt.title(\"Random Search Hyper parameter Comparison\", fontsize=25, color=\"blue\")  # setting the plot title.\n",
    "plt.plot(sorted_list1,sorted_best , \"--\", marker = \"o\", label=\"splitte best\", color=\"red\")  # setting the best\n",
    "plt.plot(sorted_list2,sorted_random ,\":\", marker = \"*\", label=\"splitte random\", color=\"blue\")  # setting the random \n",
    "                                                # variables values to the plot on the y axis and max depth on the x axis.\n",
    "plt.xlabel('max depth',fontsize=20)  # Setting the x label.\n",
    "plt.ylabel(\"Avarage CV Score\",fontsize=20)  # setting the y label.\n",
    "plt.legend(loc='upper left')  # setting the legend.\n",
    "plt.grid()  # setting a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8633aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d51c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419518b",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f77d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = list(range(101,150))  # a list with values specified.\n",
    "splitter_list = ['best', 'random']  # a list with values specified.\n",
    "para_grid = dict(max_depth = max_depth_list, splitter = splitter_list)  # adding the above \n",
    "                                                                                                       # lists in a dictinary.\n",
    "grid_search = Grid_search_fun(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_leaf_nodes = None, \\\n",
    "                                    min_weight_fraction_leaf = 0.0,criterion = 'entropy', \\\n",
    "                                    max_features = None), para_grid, 5, X_over, y_over)  # Using the grid search gunction with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0c743",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best = []  # a empty list is created\n",
    "for i in range(len(grid_search.cv_results_[\"mean_test_score\"])):  # getting all even number \n",
    "                                                                       # indexes using a for loop.\n",
    "    if grid_search.cv_results_[\"param_splitter\"][i] == \"best\":\n",
    "\n",
    "        best.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the best values to the\n",
    "                                                                      # varibale best.\n",
    "\n",
    "random = []  # a empty list is created\n",
    "for i in range(len(grid_search.cv_results_[\"mean_test_score\"])):  # getting all odd number indexes \n",
    "                                                                       # using a for loop.\n",
    "    if grid_search.cv_results_[\"param_splitter\"][i] == \"random\":\n",
    "        random.append(grid_search.cv_results_[\"mean_test_score\"][i])  # appending the random values to the \n",
    "                                                                    # varibale random.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(dpi=100, figsize=(14, 7))  # setting the plot size\n",
    "plt.title(\"Grid Search Hyper parameter Comparison with \", fontsize=25, color=\"blue\")  # setting the plot title.\n",
    "plt.plot(max_depth_list,best , \"--\", marker = \"o\", label=\"splitter best\", color=\"red\")  # setting the best\n",
    "plt.plot(max_depth_list,random ,\":\", marker = \"*\", label=\"splitter random\", color=\"blue\")  # setting the random \n",
    "                                                # variables values to the plot on the y axis and max depth on the x axis.\n",
    "plt.xlabel('Max depth',fontsize=20)  # Setting the x label.\n",
    "plt.ylabel(\"Avarage CV Score\",fontsize=20)  # setting the y label.\n",
    "plt.legend(loc='upper left')  # setting the legend.\n",
    "plt.grid()  # setting a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedc829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8a22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbf180",
   "metadata": {},
   "source": [
    "# Without any model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be6cfe",
   "metadata": {},
   "source": [
    "## Checking predicted/actual results\n",
    "## Checking testing and traning scores\n",
    "## Checking Actual values classified correctly and wrongly.\n",
    "## Checking accuracy, precision, recall and f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68632cd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_leaf_nodes = None, \\\n",
    "                                    min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "                                    max_depth =  121, splitter = 'random'), X_train_over, y_train_over, X_test_over,\\\n",
    "                                    y_test_over, \"Decision Tree\")  \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577b595",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5988127",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763e0d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(StandardScaler(), X_train_over, X_test_over, y_train_over, \\\n",
    "               y_test_over,DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2,\\\n",
    "               max_leaf_nodes = None, min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "               max_depth =  121, splitter = 'random'), \"Decision Tree\")\n",
    "\n",
    "# performs standard scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da765b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train_over, X_test_over, y_train_over,\\\n",
    "               y_test_over,DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2,\\\n",
    "               max_leaf_nodes = None, min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "               max_depth =  121, splitter = 'random') ,\"Decision Tree\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37401f12",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29422ff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(RobustScaler(), X_train_over, X_test_over, y_train_over,\\\n",
    "               y_test_over,DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2,\\\n",
    "               max_leaf_nodes = None, min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "               max_depth =  121, splitter = 'random') ,\"Decision Tree\")\n",
    "# performs robust scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5f6e5",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf773741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(Normalizer(), X_train_over, X_test_over, y_train_over,\\\n",
    "               y_test_over,DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2,\\\n",
    "               max_leaf_nodes = None, min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "               max_depth =  121, splitter = 'random') ,\"Decision Tree\")\n",
    "# Performs normalization scaling \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078be008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed35e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ce621cb",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143c686",
   "metadata": {},
   "source": [
    "# Original Results without hyperparameter Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11001977",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classifier_function(DecisionTreeClassifier(), X_train_over, y_train_over, X_test_over, y_test_over, \"Decision Tree\")  \n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1eb79",
   "metadata": {},
   "source": [
    "# Best Score and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98a8b",
   "metadata": {},
   "source": [
    "# Over Sampled X and y values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da765b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c5ab4",
   "metadata": {},
   "source": [
    "# Results with hyparameters improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6b6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featurescaling(MinMaxScaler(), X_train_over, X_test_over, y_train_over,\\\n",
    "               y_test_over,DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2,\\\n",
    "               max_leaf_nodes = None, min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "               max_depth =  121, splitter = 'random') ,\"Decision Tree\")\n",
    "# performs Minmax scaling\n",
    "# Performs traing, testing prediction.\n",
    "# performs precision, recall, f1-score and support prediction\n",
    "# plots a confusion matrix\n",
    "# returns the traing, testing, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af19f8e",
   "metadata": {},
   "source": [
    "# Un_edited full model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1df7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(DecisionTreeClassifier(), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a36b7",
   "metadata": {},
   "source": [
    "# Improved model full Evaluation with feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cec5c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossvalscore(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2,\\\n",
    "               max_leaf_nodes = None, min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "               max_depth =  121, splitter = 'random'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291b4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db2e700f",
   "metadata": {},
   "source": [
    "# Overall results and full evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f0bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_graph(list_for_plot, list_for_plot2,Accuracy_type, colour):  # funstion with given parameters.\n",
    "    \n",
    "    \"\"\"\n",
    "    The function plot_graph plots a lineargraph.\n",
    "    \n",
    "    The first parameter list_for_plot is the x axis.\n",
    "    \n",
    "    The second parameter list_for_plot2 is the y axis.\n",
    "    \n",
    "    The third parameter Accuracy_type takes a string. \n",
    "    for example \"F1 score\"\n",
    "    \n",
    "    The fourth parameter colour is the color for the bar plot.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "    plt.figure()  # plots figure\n",
    "    plt.figure(figsize = (15,10)) # sets the size of the plot\n",
    "    plt.title(\"Model Evaluation\",fontsize=18)  # Displays plot title\n",
    "    plt.plot(list_for_plot, list_for_plot2, color = colour)  # Displays description of the plots x and y labels.\n",
    "    plt.xlabel(\"Models\")  # Displays the x axis for the plot\n",
    "    plt.ylabel(Accuracy_type)  # Displays the y axis for the plot.\n",
    "    plt.grid()  # adds a gird to the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f1855",
   "metadata": {},
   "source": [
    "## k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a59cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crossvalscore(model, X, y, cv_val):  # function to perform cross validation with model X, y and cv_val as parameters\n",
    "    \"\"\"\n",
    "    The crossvalscore function finds the avarage cross validation accuracy, precison, recall, f1 score, and area uner the curve\n",
    "    of a model and its standard deveation.\n",
    "    \n",
    "    The first parameter model is the type of model to perform the cross validation on.\n",
    "    \n",
    "    The second parameter X is the features.\n",
    "    \n",
    "    The third parameter y is the labels.\n",
    "    \n",
    "    the foruth parameter cv_val is the number of times to cross validate the given model.\n",
    "    \n",
    "    The crossvalscore function returns the cross validation accuracy, precison, recall, f1 scoer, and area uner the curve\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sc = MinMaxScaler() # creating an instance of the object.\n",
    "    \n",
    "\n",
    "    X[:, 55:] = sc.fit_transform(X[:, 55:])  # Scaling x_train\n",
    "    X[:,55:] = sc.transform(X[:, 55:])  # Scaling y_train\n",
    "    scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']  # a list with values given.\n",
    "    results = []  # a empty list\n",
    "    results_std = []\n",
    "    for i in range(len(scoring)):  # looping to the leghth of the variable scoring\n",
    "        print(\"score metric = \", scoring[i])  # printing output\n",
    "        score = cross_val_score(estimator = model, X = X, y = y,scoring=scoring[i], cv = cv_val)   # performs different \n",
    "                                                                                     # tests to get best accurecy.\n",
    "        print(\"Score : \",score.mean())  # accuracy printed.\n",
    "        print(\"Standard Deviation\", score.std())  # standard deveation printed (std -avarage or std+ avarage )\n",
    "        results.append(score.mean())\n",
    "        results_std.append(score.std())\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return results[0], results_std[0], results[1],results_std[1] ,results[2],results_std[2],\\\n",
    "                                        results[3],results_std[3], results[4], results_std[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd301662",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36668a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DT_accuracy,DT_accuracy_std, DT_precision, DT_precision_std, DT_recall,DT_recall_std, DT_f1, DT_f1_std, DT_auc,\\\n",
    "               DT_auc_std = crossvalscore(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2,\\\n",
    "               max_leaf_nodes = None, min_weight_fraction_leaf = 0.0,criterion = 'entropy', max_features = None, \\\n",
    "               max_depth =  121, splitter = 'random'), X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be16441",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d0c46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RF_accuracy,RF_accuracy_std, RF_precision, RF_precision_std, RF_recall,RF_recall_std, RF_f1, RF_f1_std, RF_auc,\\\n",
    "RF_auc_std =  crossvalscore(RandomForestClassifier(n_estimators =90,min_samples_split = 2, min_samples_leaf = 1,\\\n",
    "max_depth = 50,bootstrap = False, max_features = 'sqrt', criterion = 'entropy'), X_over, y_over, 10) \n",
    "# Performs cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52367c89",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a754fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_accuracy,KNN_accuracy_std, KNN_precision, KNN_precision_std, KNN_recall,KNN_recall_std, KNN_f1,\\\n",
    "KNN_f1_std, KNN_auc, KNN_auc_std = crossvalscore(KNeighborsClassifier(n_neighbors = 15, weights ='distance'),\\\n",
    " X_over, y_over, 10)  # Performs cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877b903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = [\"KNN\",\"Decision Tree\", \"Random Forest\"]  # a list of models used.\n",
    "Sampling = [\"Over Sampled\", \"Over Sampled\", \"Over Sampled\"]  # a list of sampling techniwues used.\n",
    "scalars = [\"MInMax Scalar\", \"MinMax Scalar\", \"MinMax Scalar\"]  # a list of types of scaling techniques used.\n",
    "\n",
    "mean_accuracy = [KNN_accuracy,DT_accuracy,RF_accuracy]  # a list of model train accuracy\n",
    "standard_deaviation = [KNN_accuracy_std,DT_accuracy_std,RF_accuracy_std]  # a list of model train standard deveation.\n",
    "\n",
    "mean_precision = [KNN_precision,DT_precision,RF_precision]  # a list of model precision score\n",
    "precision_standard_deaviation  = [KNN_precision_std,DT_precision_std,RF_precision_std]  # a list of model precision \n",
    "                                                                                 # standard deveation.\n",
    "\n",
    "mean_recall = [KNN_recall,DT_recall,RF_recall]  # a list of model recall score\n",
    "recall_standard_deaviation  = [KNN_recall_std,DT_recall_std,RF_recall_std]  # a list of model recall standard deveation.\n",
    "\n",
    "mean_f1_score = [KNN_f1,DT_f1,RF_f1]  # a list of model f1 score\n",
    "f1_score_standard_deaviation  = [KNN_f1_std,DT_f1_std,RF_f1_std]  # a list of model f1 score standard deveation.\n",
    "\n",
    "mean_Area_under_curve = [KNN_auc,DT_auc,RF_auc]  # a list of model area under curve score\n",
    "Area_under_curve_standard_deaviation  = [KNN_auc_std,DT_auc_std,RF_auc_std]  # a list of model area under curve\n",
    "                                                                            #  standard deveation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955e07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation = pd.DataFrame({\n",
    "    'Model':model_name,\n",
    "    'Sampling': Sampling,\n",
    "    'scalar type':scalars,\n",
    "    'Mean_accuracy':mean_accuracy,\n",
    "    'Mean Accuracy Standard Deaviation':standard_deaviation ,\n",
    "    'Mean Precision':mean_precision,\n",
    "    'Precision Standard Deaviation':precision_standard_deaviation ,\n",
    "    'Mean Recall':mean_recall, \n",
    "    'Recall Standard Deaviation':recall_standard_deaviation , \n",
    "    'Mean f1 score':mean_f1_score,\n",
    "    'f1 score Standard Deaviation':f1_score_standard_deaviation ,\n",
    "    'Mean Area under curve':mean_Area_under_curve, \n",
    "    'Area under curve Standard Deaviation':Area_under_curve_standard_deaviation \n",
    "})   # using lists to make a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03124039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation   # viewing dataframe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0466a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation.sort_values(by='Mean f1 score', ascending=False)  # viewing dataframe information by f1 score in decending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10241a9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation.sort_values(by='Mean Recall', ascending=False)  # viewing dataframe information by recall in decending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af9e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation.sort_values(by='Mean Area under curve', ascending=False)  # viewing dataframe information by area under the curve\n",
    "                                                                    # in decending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c5764",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_bar_graph(model_name, mean_f1_score, \"f1 score\", \"red\")  # functions argents given. plots output using given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f745305",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_bar_graph(model_name, mean_recall, \"Recall\", \"blue\")  # functions argents given. plots output using given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3639a8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_graph(model_name, mean_Area_under_curve, \"Area Under Curve\", \"black\")  # functions argents given. plots output\n",
    "                                                                           # using given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8279df6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_graph(model_name, mean_f1_score, \"f1_score\", \"black\")  # functions argents given. plots output using given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4605e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_graph(model_name, mean_f1_score, \"f1_score\", \"black\")  # functions argents given. plots output using given data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
